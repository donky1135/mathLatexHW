{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dc0e15f-5077-4d32-9504-2018f5540ec1",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc0d5683-32ba-44ad-9881-10bdf3408ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import func3\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b52eced-7bfb-4f15-81f5-e55d6c378945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqGen(n, ratio):\n",
    "    ind = random.sample(range(10), 5)\n",
    "    ind.sort()\n",
    "    randmu = 2*torch.rand((5)) - 1\n",
    "    T = random.randint(0, n)\n",
    "    haspoint = random.random()\n",
    "    seq = torch.randn((n,10))\n",
    "    haschange = False\n",
    "    if haspoint <= ratio:\n",
    "        haschange = True\n",
    "        for t in range(n):\n",
    "                j = 0\n",
    "                for i in range(10):\n",
    "                    if i in ind:\n",
    "                        seq[t][i] = seq[t][i] + randmu[j]\n",
    "                        j = j+1\n",
    "        \n",
    "        \n",
    "        \n",
    "    return seq, ind, randmu, haschange, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d60e1b3a-79a6-47bf-8a3a-f4851b249985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "[1, 2, 6, 7, 8]\n",
      "tensor([-0.9562, -0.3473, -0.9875,  0.1532, -0.2156])\n",
      "0.6161402811144422 32\n",
      "0 tensor([-0.8207,  0.1794,  0.3079,  1.6066, -0.4839, -0.7526, -2.0831,  1.8277,\n",
      "        -0.1502,  0.3111])\n",
      "1 tensor([-0.2142, -1.0767,  0.4379, -0.2036, -0.5312,  0.1712, -1.0970, -0.1783,\n",
      "         0.9725,  1.3602])\n",
      "2 tensor([ 0.5295, -1.6347, -1.7138, -0.1080, -1.4227, -0.2295, -3.5396, -0.7612,\n",
      "        -0.0229, -1.0080])\n",
      "3 tensor([ 0.1370, -2.4191,  0.1669, -0.5856,  1.0850,  0.2412, -2.5732,  0.5730,\n",
      "        -1.6587,  2.1049])\n",
      "4 tensor([ 0.1950, -1.4301,  0.8942, -0.4636,  0.4511, -1.3616, -2.6730, -0.4233,\n",
      "         0.4155, -1.8123])\n",
      "5 tensor([ 0.5021, -1.9498,  1.4541, -0.6365,  0.8206,  1.6822, -0.5846, -1.8780,\n",
      "         0.7893,  1.2262])\n",
      "6 tensor([ 2.2820, -1.8379,  0.4255, -1.2552, -1.9233,  0.0566, -0.8474, -0.0619,\n",
      "        -1.3124, -1.2023])\n",
      "7 tensor([ 0.7467, -1.6236,  1.7891,  0.6751, -1.5157, -0.5240, -1.5478,  0.0749,\n",
      "        -2.2192, -0.0554])\n",
      "8 tensor([-0.3317, -1.1479, -0.6431, -0.8336, -0.4878,  0.9498,  0.3702, -0.3619,\n",
      "        -0.6403, -0.3130])\n",
      "9 tensor([ 0.0427, -0.4701, -0.6875,  0.3156,  0.2483,  0.7862, -1.9295,  1.1453,\n",
      "        -0.4552,  0.9877])\n",
      "10 tensor([-0.7264,  0.4268,  0.2399, -1.6592,  1.3702,  1.1743, -0.7609, -1.7007,\n",
      "        -0.2308,  1.1703])\n",
      "11 tensor([ 1.2963,  0.6202,  0.1879, -0.5501, -1.0581,  1.2883, -0.4384, -0.0068,\n",
      "        -1.8337, -0.2490])\n",
      "12 tensor([ 2.0594, -1.2372, -0.6629,  0.1657, -0.4039,  3.0873, -2.1235,  0.6137,\n",
      "        -1.9270,  0.0258])\n",
      "13 tensor([-0.0512, -1.3514, -1.1828, -0.5195,  1.1534,  0.9828, -0.4848, -0.7895,\n",
      "         0.5263, -0.5963])\n",
      "14 tensor([-0.2038, -1.0236, -0.3511, -0.0525, -0.8279, -0.5609, -1.3086, -1.0568,\n",
      "         0.3962, -0.2257])\n",
      "15 tensor([ 0.2827, -0.7232, -1.7130,  1.0259, -0.1708,  1.1390, -0.0591,  1.4339,\n",
      "        -0.5922, -0.6315])\n",
      "16 tensor([ 0.4259,  0.3105,  0.7577, -1.5364, -0.1309,  1.6462, -3.4684,  0.2698,\n",
      "         0.6937,  0.6036])\n",
      "17 tensor([-0.7802, -1.3054,  0.3520,  0.3999, -0.1299,  0.2365, -3.6587,  1.1396,\n",
      "         1.7791, -0.1453])\n",
      "18 tensor([ 1.5140, -0.7352, -0.2289, -0.1941,  0.9446, -0.6643,  0.2741,  1.1399,\n",
      "        -0.4073,  3.1913])\n",
      "19 tensor([ 1.1461, -1.0141, -1.6668, -0.8688, -0.5514, -1.3027, -0.0328,  0.3790,\n",
      "         0.0600, -0.1807])\n",
      "20 tensor([ 0.3139, -3.3017, -0.5058,  0.8513, -0.1385, -0.7207, -0.0137,  1.1183,\n",
      "         0.0420,  2.1492])\n",
      "21 tensor([ 0.9116, -2.3968,  0.8690,  0.0509, -1.2512, -0.8802,  0.1740, -0.4139,\n",
      "        -0.3949,  0.1696])\n",
      "22 tensor([ 0.1606, -0.1929, -2.0758,  0.0466, -0.1401, -0.0838,  0.0752, -0.8827,\n",
      "         0.3723, -1.7049])\n",
      "23 tensor([ 0.9732, -2.1842, -3.4199,  0.3497, -0.1572,  0.8394, -2.5524,  1.0572,\n",
      "        -1.3296,  1.2638])\n",
      "24 tensor([ 0.7018, -0.4137, -2.0820, -1.8370,  0.2878, -1.7844, -2.6749, -1.0149,\n",
      "         0.6821, -0.7541])\n",
      "25 tensor([-0.0782, -2.2193,  1.0253, -0.0908,  0.7127,  1.4419, -0.7022,  0.7304,\n",
      "        -0.6838,  0.3092])\n",
      "26 tensor([-1.7411, -0.4429,  0.1981, -0.2094, -1.3289, -0.0561, -1.4164,  1.2066,\n",
      "         0.7222,  0.8438])\n",
      "27 tensor([-0.2360,  0.9469, -0.8412,  1.5721,  0.0079,  0.9482,  0.7958,  1.9662,\n",
      "         1.0941, -0.1520])\n",
      "28 tensor([ 0.8370, -0.8091, -1.5732, -0.7584, -1.2109, -1.2792,  1.6737,  1.3435,\n",
      "         1.3263, -0.1695])\n",
      "29 tensor([ 0.1941,  0.4557,  0.1908,  0.2825,  1.4526,  0.2193, -0.6829,  0.1248,\n",
      "        -1.0038,  0.3054])\n",
      "30 tensor([-2.4664, -1.0957,  0.4358, -0.2206,  0.2540, -0.9400, -0.9025,  0.2530,\n",
      "        -0.8123,  2.4073])\n",
      "31 tensor([-0.2226, -0.8222, -2.8959, -0.4822, -0.5269,  0.5505, -3.0565,  0.4287,\n",
      "        -1.9379, -1.2390])\n",
      "32 tensor([ 2.2179, -1.0257,  0.7195, -1.3503, -0.5949, -0.6649,  0.9320, -0.1483,\n",
      "         0.3584,  1.9230])\n",
      "33 tensor([ 0.0172,  0.1460,  0.7817, -1.0988, -0.1113,  0.2191, -0.9100,  1.1506,\n",
      "         0.9552,  0.6159])\n",
      "34 tensor([ 0.2359, -0.5783, -1.0224, -0.7034,  0.4856, -0.7187,  0.0600,  1.7021,\n",
      "        -0.8951,  0.6386])\n",
      "35 tensor([ 1.0481, -0.7586,  1.4140,  0.0232, -2.1374, -2.9923, -0.7614, -1.0918,\n",
      "         1.5403, -1.5160])\n",
      "36 tensor([-2.3617, -0.7438, -1.2293, -0.3397,  1.0523, -0.3216, -1.2497,  2.2440,\n",
      "         0.8689,  0.8730])\n",
      "37 tensor([ 1.1343,  0.0384, -1.2858, -0.1395, -0.3720, -1.3857, -0.5083,  1.2094,\n",
      "         1.8681, -0.3270])\n",
      "38 tensor([ 1.0653, -1.5084, -0.5895, -1.4850, -1.2288,  0.6012, -0.5131,  0.9079,\n",
      "         1.0501,  0.4438])\n",
      "39 tensor([-1.3559, -0.6309, -0.6518, -0.5059,  0.3646,  1.0136, -0.7764,  0.9950,\n",
      "         0.1789, -0.3249])\n",
      "40 tensor([ 0.2897, -0.4734, -0.8220, -1.0959, -1.5107,  0.2487, -1.0132,  0.6972,\n",
      "        -0.4905,  0.4704])\n",
      "41 tensor([-0.3715, -0.7384, -0.3297,  0.4870, -0.2368, -0.7318, -3.8826,  0.4033,\n",
      "         0.0052, -0.0245])\n",
      "42 tensor([-1.3670, -0.8804,  1.2980, -0.7038, -0.9758, -0.6962, -2.4859,  1.7952,\n",
      "        -0.4067,  0.3147])\n",
      "43 tensor([ 1.4550, -0.8964,  1.7744,  1.0458,  0.0460, -1.9887, -0.6888,  1.1571,\n",
      "        -1.0823, -0.7572])\n",
      "44 tensor([ 0.0738, -2.0093, -0.3929, -0.2345,  0.3049,  0.0195, -1.3605, -0.0834,\n",
      "        -1.0030, -0.5915])\n",
      "45 tensor([-0.6067, -1.6855, -0.8935,  1.1589,  0.9653,  0.8151, -1.6615,  1.2381,\n",
      "         0.0158, -0.1603])\n",
      "46 tensor([ 0.8498,  1.8800, -0.6960,  1.0809, -1.5723,  0.8616, -0.4913,  0.8428,\n",
      "        -0.3072,  1.6369])\n",
      "47 tensor([ 0.8448, -1.6795, -1.2136,  0.1681, -0.0153,  0.6089, -1.1625, -1.8104,\n",
      "         0.0280, -0.5815])\n",
      "48 tensor([-1.2901,  0.5179, -1.5240,  0.1285, -0.0227,  0.1577, -0.1523, -1.4001,\n",
      "        -0.1005, -2.0535])\n",
      "49 tensor([-1.3494, -2.0421,  0.5067,  0.4519, -1.7181,  0.2881,  2.3673,  0.6069,\n",
      "        -0.3579,  0.7844])\n"
     ]
    }
   ],
   "source": [
    "seq, ind, randmu, haspoint, T = seqGen(50, 0.8)\n",
    "print(len(seq))\n",
    "print(ind)\n",
    "print(randmu)\n",
    "print(haspoint, T)\n",
    "for i in range(len(seq)):\n",
    "    print(i, seq[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970e090d-6507-4e44-99cc-4ccad20acd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class changeDetectRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(changeDetectRNN, self).__init__()\n",
    "        self.current_itemf = torch.nn.Linear( in_features = 10, out_features = 100, bias = True )\n",
    "        self.current_itemb = torch.nn.Linear( in_features = 10, out_features = 100, bias = True )\n",
    "\n",
    "        self.prev_itemf1 = torch.nn.Linear( in_features = 100, out_features = 100, bias = False )\n",
    "        self.prev_itemb1 = torch.nn.Linear( in_features = 100, out_features = 100, bias = False )\n",
    "\n",
    "        self.prev_itemf2 = torch.nn.Linear( in_features = 100, out_features = 100, bias = False )\n",
    "        self.prev_itemb2 = torch.nn.Linear( in_features = 100, out_features = 100, bias = False )\n",
    "\n",
    "        self.prev_itemf3 = torch.nn.Linear( in_features = 100, out_features = 100, bias = False )\n",
    "        self.prev_itemb3 = torch.nn.Linear( in_features = 100, out_features = 100, bias = False )\n",
    "\n",
    "        \n",
    "        self.normf = nn.LayerNorm(100)\n",
    "        self.normb = nn.LayerNorm(100)\n",
    "        \n",
    "        self.point_detector = nn.Sequential(nn.Linear(200,1000), nn.LayerNorm(1000),nn.Sigmoid(),nn.Linear(1000,1000),nn.Sigmoid(), nn.LayerNorm(1000), nn.Linear(1000,1),nn.Sigmoid() )\n",
    "    def forward(self, seq):\n",
    "        n = seq.shape[1]\n",
    "        batch_size = seq.shape[0]\n",
    "        seqb = torch.flip(seq, [1])\n",
    "        yf = []\n",
    "        yb = []\n",
    "        yf.append(nn.Sigmoid()(self.normf(self.current_itemf(seq[:,0,:]))))\n",
    "        yb.append(nn.Sigmoid()(self.normb(self.current_itemb(seqb[:,0,:]))))\n",
    "        yf.append(nn.Sigmoid()(self.normf(self.current_itemf(seq[:,1,:])+ self.prev_itemf1(yf[-1]))))\n",
    "        yb.append(nn.Sigmoid()(self.normb(self.current_itemb(seqb[:,1,:])+ self.prev_itemb1(yb[-1]))))\n",
    "        yf.append(nn.Sigmoid()(self.normf(self.current_itemf(seq[:,2,:]) + self.prev_itemf1(yf[-1])+ self.prev_itemf2(yf[-2]))))\n",
    "        yb.append(nn.Sigmoid()(self.normb(self.current_itemb(seqb[:,2,:]) + self.prev_itemb1(yb[-1])+ self.prev_itemb2(yf[-2]))))\n",
    "        for i in range(3,n):\n",
    "            # print(yf[-1].shape)\n",
    "            yf.append(nn.Sigmoid()(self.normf(self.current_itemf(seq[:,i,:]) + self.prev_itemf1(yf[-1])+ self.prev_itemf2(yf[-2])+self.prev_itemf3(yf[-3]))))\n",
    "            yb.append(nn.Sigmoid()(self.normb(self.current_itemb(seqb[:,i,:]) + self.prev_itemb1(yb[-1])+ self.prev_itemb2(yf[-2])+self.prev_itemb3(yf[-3]))))\n",
    "        yb.reverse()\n",
    "\n",
    "        changepoints = torch.zeros((batch_size, n))\n",
    "        \n",
    "        for i in range(n):\n",
    "            \n",
    "            changepoints[:,i] = self.point_detector(torch.cat((yf[i], yb[i]), 1))[:,0]\n",
    "\n",
    "        return changepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b53e87b-0eb1-4a17-ba7a-763d0c86a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class changeDetectLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(changeDetectLSTM, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(10, 20,1,batch_first=True, bidirectional=True)\n",
    "        #  nn.LSTM(10, 20,5,batch_first=True, bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(10, 5,3,batch_first=True)\n",
    "        \n",
    "        self.classifierSimp = nn.Linear(40,1)\n",
    "        \n",
    "        self.classifyLSTM = nn.LSTM(20, 1, 1, batch_first=True)\n",
    "        self.classifier = nn.Sequential(nn.Linear(20,200), nn.ELU(), nn.LayerNorm(200),\n",
    "                                        nn.Linear(200,100), nn.ELU(), nn.LayerNorm(100), nn.Linear(100,1))\n",
    "        self.point_detector = nn.Sequential(nn.Linear(200,1000), nn.LayerNorm(1000),nn.Sigmoid(),nn.Linear(1000,1000),nn.Sigmoid(), nn.LayerNorm(1000), nn.Linear(1000,1),nn.Sigmoid() )\n",
    "\n",
    "    \n",
    "    def forward(self, seq):\n",
    "        # seq = torch.mul(seq, 10)\n",
    "        seq, _ = self.lstm1(seq)\n",
    "        seq, _ = self.classifyLSTM(seq)\n",
    "        \n",
    "        return seq[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd1c174f-88aa-4cff-88a0-705212367651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.4984, -0.3807, -0.4210,  0.1526,  0.1696,  0.4242,  0.7521,  0.1741,\n",
      "         0.8790,  0.4640])\n",
      "tensor([ 1.4984, -0.3807, -0.4210,  0.1526,  0.1696,  0.4242,  0.7521,  0.1741,\n",
      "         0.8790,  0.4640,  1.4984, -0.3807, -0.4210,  0.1526,  0.1696,  0.4242,\n",
      "         0.7521,  0.1741,  0.8790,  0.4640])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10)\n",
    "print(x)\n",
    "print(torch.cat((x,x), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "643802e1-513a-476b-b4f5-72c847387da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size, seq_length, ratio, device):\n",
    "    x_batch = torch.zeros((batch_size, seq_length, 10), device=device)\n",
    "    y_batch = torch.zeros((batch_size, seq_length), device=device)\n",
    "    indices = []\n",
    "    for i in range(batch_size):\n",
    "        seq, _, _, haschange, T = seqGen(seq_length, ratio)\n",
    "        if haschange:\n",
    "            indices.append(T)\n",
    "        else:\n",
    "            indices.append(-1)\n",
    "        for j in range(len(seq)):\n",
    "            if haschange  and j >= T:\n",
    "                y_batch[i][j] = 1\n",
    "            \n",
    "        x_batch[i] = seq\n",
    "    return x_batch, y_batch,indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bc3ec4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch1(x, y, batch_size):\n",
    "    n = x.shape[0]\n",
    "\n",
    "    batch_indices = random.sample( [ i for i in range(n) ], k = batch_size )\n",
    "\n",
    "    x_batch = x[ batch_indices ]\n",
    "    y_batch = y[ batch_indices ]\n",
    "`\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a000aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_present(modeled, T, seq):\n",
    "    values = []\n",
    "    for i in range(11):\n",
    "        if i - 5 + T > 100:\n",
    "            values.append(1.0)\n",
    "        else:\n",
    "            values.append(modeled[i - 5 + T].item())\n",
    "    plt.scatter([i-5 for i in range(11)], values)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f216d060-2593-4691-b7b2-03e8e90fe1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = changeDetectLSTM()\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "\n",
    "x_test, y_test, _ = get_batch(1000,100, 1, device)\n",
    "for epoch in range(40):\n",
    "    totalLoss = 0\n",
    "    for i in range(2**10):\n",
    "        L = random.randint(2,100)\n",
    "        # L = 10\n",
    "        x_batch, y_batch, _ = get_batch(1, L, 0.8, device=device)\n",
    "        optimizer.zero_grad \n",
    "        # print(y_batch.shape)\n",
    "        output = model.forward(x_batch)\n",
    "        # print(output.shape)\n",
    "        # print(y_batch[0])\n",
    "#         print(output.shape)\n",
    "#         print(y_batch.shape)\n",
    "        loss = torch.nn.CrossEntropyLoss()(output, y_batch)\n",
    "        totalLoss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print((epoch+1),\"Test loss\",torch.nn.CrossEntropyLoss(reduction='mean')(model.forward(x_test), y_test).item(), \"Training loss\", totalLoss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f535e0a0-e311-4f6a-9fb8-9ee6b50ab8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[0.3183, 0.2762, 0.2705, 0.2709, 0.2720, 0.2729, 0.2757, 0.2805, 0.2883,\n",
      "         0.3004, 0.3183, 0.3358, 0.3624, 0.3910, 0.4192, 0.4574, 0.4777, 0.4989,\n",
      "         0.5176, 0.5342, 0.5443, 0.5577, 0.5698, 0.5807, 0.5902, 0.5948, 0.6031,\n",
      "         0.6109, 0.6169, 0.6208, 0.6269, 0.6322, 0.6347, 0.6371, 0.6422, 0.6452,\n",
      "         0.6464, 0.6482, 0.6523, 0.6566, 0.6601, 0.6636, 0.6651, 0.6663, 0.6692,\n",
      "         0.6719, 0.6744, 0.6768, 0.6791, 0.6813, 0.6830, 0.6858, 0.6876, 0.6893,\n",
      "         0.6910, 0.6925, 0.6940, 0.6960, 0.6973, 0.6986, 0.6999, 0.7010, 0.7021,\n",
      "         0.7030, 0.7040, 0.7050, 0.7059, 0.7068, 0.7081, 0.7089, 0.7097, 0.7104,\n",
      "         0.7108, 0.7111, 0.7118, 0.7124, 0.7131, 0.7137, 0.7142, 0.7147, 0.7153,\n",
      "         0.7158, 0.7163, 0.7166, 0.7170, 0.7172, 0.7174, 0.7178, 0.7186, 0.7188,\n",
      "         0.7193, 0.7195, 0.7199, 0.7201, 0.7204, 0.7208, 0.7211, 0.7214, 0.7215,\n",
      "         0.7215]], grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVU0lEQVR4nO3df2xd933e8fcTWnI4xwP/MItClFRpiSJMtoIou1WyeUUK167kObVUpwNko6uHDVMMWGiKuFqkxSg69w871qAWQ4V1wuCiaGsIbqeo2tyUbeIUm4061VWoRKBdzozS2rrKFnk162VhrB999gcPsyuaEi/FSx7dL58XYJjfH4f6HBh4fPQ933OObBMREeV6T90FRETE4krQR0QULkEfEVG4BH1EROES9BERhbup7gJmuu2227xu3bq6y4iI6CknT5580/bgbGM3XNCvW7eOZrNZdxkRET1F0l9dbSxLNxERhUvQR0QULkEfEVG4BH1EROE6CnpJ2yWNSRqXtO8a8z4pyZIaVfseSSclna7+fVe3Co+IiM7MuetGUh9wCLgHOAuckHTc9isz5t0KfBr4alv3m8BP2T4n6Q5gGBjqVvERESU4NtLiwPAY5yYmWTXQz95tG9m5pXtR2ckV/VZg3PYZ2xeAI8COWeb9CvB54PvTHbZHbJ+rmqNAv6SbF1hzREQxjo202H/0NK2JSQy0JibZf/Q0x0ZaXfszOgn6IeCNtvZZZlyVS/oIsMb289f4PZ8Evmb7nZkDknZLakpqnj9/voOSIiLKcGB4jMmLl6/om7x4mQPDY137MxZ8M1bSe4CDwGPXmHM7U1f7n5pt3PZh2w3bjcHBWR/siogo0rmJyXn1X49Ogr4FrGlrr676pt0K3AH8qaS/BD4GHG+7Ibsa+ALwc7a/2Y2iIyJKsWqgf17916OToD8BbJC0XtJKYBdwfHrQ9t/Yvs32OtvrgJeB+203JQ0AzwP7bL/UtaojIgqxd9tG+lf0XdHXv6KPvds2du3PmDPobV8C9jC1Y+ZV4Dnbo5KekHT/HIfvAT4A/JKkU9U/P7TgqiMiCrFzyxBPPrCZoYF+BAwN9PPkA5u7uutGN9o3YxuNhvNSs4iI+ZF00nZjtrE8GRsRUbgEfURE4RL0ERGFS9BHRBQuQR8RUbgEfURE4RL0ERGFS9BHRBQuQR8RUbgEfURE4RL0ERGFS9BHRBQuQR8RUbgEfURE4RL0ERGFS9BHRBQuQR8RUbgEfURE4ToKeknbJY1JGpe07xrzPinJkhptffur48YkbetG0RER0bmb5pogqQ84BNwDnAVOSDpu+5UZ824FPg18ta1vE7ALuB1YBXxJ0gdtX+7eKURExLV0ckW/FRi3fcb2BeAIsGOWeb8CfB74flvfDuCI7XdsfwsYr35fREQskU6Cfgh4o619tur7AUkfAdbYfn6+x1bH75bUlNQ8f/58R4VHRERnFnwzVtJ7gIPAY9f7O2wftt2w3RgcHFxoSRER0WbONXqgBaxpa6+u+qbdCtwB/KkkgB8Gjku6v4NjIyJikXVyRX8C2CBpvaSVTN1cPT49aPtvbN9me53tdcDLwP22m9W8XZJulrQe2AD8edfPIiIirmrOK3rblyTtAYaBPuAZ26OSngCato9f49hRSc8BrwCXgEez4yYiYmnJdt01XKHRaLjZbNZdRkRET5F00nZjtrE8GRsRUbgEfURE4RL0ERGF62R7ZURE8Y6NtDgwPMa5iUlWDfSzd9tGdm551/OdPSlBHxHL3rGRFvuPnmby4tSmwNbEJPuPngYoIuyzdBMRy96B4bEfhPy0yYuXOTA8VlNF3ZWgj4hl79zE5Lz6e02CPiKWvVUD/fPq7zUJ+ohY9vZu20j/ir4r+vpX9LF328aaKuqu3IyNiGVv+oZrdt1ERBRs55ahYoJ9pizdREQULkEfEVG4BH1EROES9BERhUvQR0QULkEfEVG4BH1EROE6CnpJ2yWNSRqXtG+W8UcknZZ0StKLkjZV/Ssk/VY19qqk/d0+gYiIuLY5g15SH3AIuBfYBDw4HeRtnrW92faHgaeBg1X/PwVutr0Z+AfApySt61LtERHRgU6u6LcC47bP2L4AHAF2tE+w/XZb8xZg+ovjBm6RdBPQD1wA2udGRMQi6yToh4A32tpnq74rSHpU0jeZuqL/+ar794H/C3wbeB34d7b/epZjd0tqSmqeP39+nqcQERHX0rWbsbYP2X4/8Fng8ap7K3AZWAWsBx6T9PdmOfaw7YbtxuDgYLdKiogIOgv6FrCmrb266ruaI8DO6ueHgD+yfdH2d4CXgMZ11BkREdepk6A/AWyQtF7SSmAXcLx9gqQNbc37gNeqn18H7qrm3AJ8DPiLhRYdERGdm/M1xbYvSdoDDAN9wDO2RyU9ATRtHwf2SLobuAi8BTxcHX4I+E1Jo4CA37T9jcU4kYiImJ1szz1rCTUaDTebzbrLiIjoKZJO2p51aTxPxkZEFC5BHxFRuAR9REThEvQREYVL0EdEFC5BHxFRuAR9REThEvQREYVL0EdEFC5BHxFRuAR9REThEvQREYVL0EdEFC5BHxFRuAR9RETh5vzwSETEUjo20uLA8BjnJiZZNdDP3m0b2bllqO6yelqCPiJuGMdGWuw/eprJi5cBaE1Msv/oaYCE/QJk6SYibhgHhsd+EPLTJi9e5sDwWE0VlaGjoJe0XdKYpHFJ+2YZf0TSaUmnJL0oaVPb2Ick/Zmk0WrOe7t5AhFRjnMTk/Pqj87MGfSS+pj6yPe9wCbgwfYgrzxre7PtDwNPAwerY28Cfgd4xPbtwI8z9QHxiIh3WTXQP6/+6EwnV/RbgXHbZ2xfAI4AO9on2H67rXkLMP3F8Z8EvmH769W8/237yr+XRURU9m7bSP+Kviv6+lf0sXfbxpoqKkMnN2OHgDfa2meBj86cJOlR4DPASuCuqvuDgCUNA4PAEdtPz3LsbmA3wNq1a+dTf0QUZPqGa3bddFfXdt3YPgQckvQQ8DjwcPX7/zHwo8D3gC9LOmn7yzOOPQwcBmg0GiYilq2dW4YS7F3WydJNC1jT1l5d9V3NEWBn9fNZ4L/ZftP294A/BD5yHXVGRMR16iToTwAbJK2XtBLYBRxvnyBpQ1vzPuC16udhYLOkv1PdmP048MrCy46IiE7NuXRj+5KkPUyFdh/wjO1RSU8ATdvHgT2S7mZqR81bTC3bYPstSQeZ+p+FgT+0/fwinUtERMxC9o21JN5oNNxsNusuIyKip1T3PxuzjeXJ2IiIwiXoIyIKl6CPiChcgj4ionAJ+oiIwiXoIyIKl6CPiChcgj4ionAJ+oiIwiXoIyIKl6CPiChcgj4ionAJ+oiIwiXoIyIKl6CPiChcgj4ionAJ+oiIwnUU9JK2SxqTNC5p3yzjj0g6LemUpBclbZoxvlbSdyX9YrcKj4iIzswZ9JL6gEPAvcAm4MGZQQ48a3uz7Q8DTwMHZ4wfBL648HIjImK+Ormi3wqM2z5j+wJwBNjRPsH2223NW5j6EDgAknYC3wJGF1xtRETMWydBPwS80dY+W/VdQdKjkr7J1BX9z1d97wM+C/zbhZcaERHXo2s3Y20fsv1+poL98ar7l4Fftf3dax0rabekpqTm+fPnu1VSREQAN3UwpwWsaWuvrvqu5gjwH6qfPwr8jKSngQHgbyV93/avtx9g+zBwGKDRaJiIiOiaToL+BLBB0nqmAn4X8FD7BEkbbL9WNe8DXgOw/WNtc34Z+O7MkI+IG9OxkRYHhsc4NzHJqoF+9m7byM4t71q1jR4wZ9DbviRpDzAM9AHP2B6V9ATQtH0c2CPpbuAi8Bbw8GIWHRGL69hIi/1HTzN58TIArYlJ9h89DZCw70Gyb6yVkkaj4WazWXcZEcvanU+9QGti8l39QwP9vLTvrhoqirlIOmm7MdtYnoyNiHc5N0vIX6s/bmwJ+oh4l1UD/fPqjxtbgj4i3mXvto30r+i7oq9/RR97t22sqaJYiE523UTEMjN9wzW7bsqQoI+IWe3cMpRgL0SWbiIiCpegj4goXII+IqJwCfqIiMIl6CMiCpegj4goXII+IqJwCfqIiMIl6CMiCpegj4goXII+IqJwCfqIiMIl6CMiCtdR0EvaLmlM0rikfbOMPyLptKRTkl6UtKnqv0fSyWrspKR8gywiYonNGfSS+oBDwL3AJuDB6SBv86ztzbY/DDwNHKz63wR+yvZmpj4Y/tvdKjwiIjrTyRX9VmDc9hnbF4AjwI72CbbfbmveArjqH7F9ruofBfol3bzwsiMiolOdfHhkCHijrX0W+OjMSZIeBT4DrARmW6L5JPA12+/McuxuYDfA2rVrOygpYnk4NtLKV55iwbp2M9b2IdvvBz4LPN4+Jul24PPAp65y7GHbDduNwcHBbpUU0dOOjbTYf/Q0rYlJDLQmJtl/9DTHRlp1lxY9ppOgbwFr2tqrq76rOQLsnG5IWg18Afg529+8jhojlqUDw2NMXrx8Rd/kxcscGB6rqaLoVZ0E/Qlgg6T1klYCu4Dj7RMkbWhr3ge8VvUPAM8D+2y/1JWKI5aJcxOT8+qPuJo5g972JWAPMAy8Cjxne1TSE5Lur6btkTQq6RRT6/QPT/cDHwB+qdp6eUrSD3X9LCIKtGqgf179EVcj23XXcIVGo+Fms1l3GRG1m16jb1++6V/Rx5MPbM4N2XgXSSdtN2Yb62TXTUTUYDrMs+smFipBH3ED27llKMEeC5Z33UREFC5BHxFRuAR9REThEvQREYVL0EdEFC5BHxFRuAR9REThEvQREYVL0EdEFC5BHxFRuAR9REThEvQREYVL0EdEFC5BHxFRuAR9REThEvQREYXrKOglbZc0Jmlc0r5Zxh+RdLr6JuyLkja1je2vjhuTtK2bxUcslWMjLe586gXW73ueO596gWMjrbpLiujYnF+YktQHHALuAc4CJyQdt/1K27Rnbf9GNf9+4CCwvQr8XcDtwCrgS5I+aPsyET1i5rdbWxOT7D96GiBff4qe0MkV/VZg3PYZ2xeAI8CO9gm2325r3gJMf3F8B3DE9ju2vwWMV78vomccGB674gPdAJMXL3NgeKymiiLmp5Nvxg4Bb7S1zwIfnTlJ0qPAZ4CVwF1tx74849h3XQJJ2g3sBli7dm0ndUcsmXMTk/Pqj7jRdO1mrO1Dtt8PfBZ4fJ7HHrbdsN0YHBzsVkkRXbFqoH9e/RE3mk6CvgWsaWuvrvqu5giw8zqPjbjh7N22kf4VfVf09a/oY++2jTVVFDE/nQT9CWCDpPWSVjJ1c/V4+wRJG9qa9wGvVT8fB3ZJulnSemAD8OcLLzti6ezcMsSTD2xmaKAfAUMD/Tz5wObciI2eMecave1LkvYAw0Af8IztUUlPAE3bx4E9ku4GLgJvAQ9Xx45Keg54BbgEPJodN9GLdm4ZSrBHz5LtuWctoUaj4WazWXcZERE9RdJJ243ZxvJkbERE4RL0ERGFS9BHRBQuQR8RUbgEfURE4RL0ERGFS9BHRBSuk5eaRdwQjo20ODA8xrmJSVYN9LN328Y8xBTRgQR99IS8Ez7i+mXpJnpC3gkfcf0S9NET8k74iOuXoI+ekHfCR1y/BH30hLwTPuL65WZs9ITpG67ZdRMxfwn66Bl5J3zE9cnSTURE4RL0ERGFy9JNzFueUI3oLR1d0UvaLmlM0rikfbOMf0bSK5K+IenLkn6kbexpSaOSXpX07yWpmycQS2v6CdXWxCTm/z+hemykVXdpEXEVcwa9pD7gEHAvsAl4UNKmGdNGgIbtDwG/DzxdHfuPgDuBDwF3AD8KfLxr1ceSyxOqEb2nkyv6rcC47TO2LwBHgB3tE2x/xfb3qubLwOrpIeC9wErgZmAF8L+6UXjUI0+oRvSeToJ+CHijrX226ruafwl8EcD2nwFfAb5d/TNs+9WZB0jaLakpqXn+/PlOa48a5AnViN7T1V03kn4WaAAHqvYHgL/P1BX+EHCXpB+beZztw7YbthuDg4PdLCm6LE+oRvSeTnbdtIA1be3VVd8VJN0NfA74uO13qu6fBl62/d1qzheBfwj894UUHfXJE6oRvaeToD8BbJC0nqmA3wU81D5B0hbgPwLbbX+nbeh14F9JehIQUzdif60LdS97dW5xzBOqEb1lzqC3fUnSHmAY6AOesT0q6Qmgafs4U0s17wN+r9o9+brt+5nagXMXcJqpG7N/ZPu/LM6pLB/5CEdEzIds113DFRqNhpvNZt1l3NDufOoFWrPschka6OelfXfVUFFE1E3SSduN2cbyCoQelC2OETEfeQXCAtWxVr5qoH/WK/pscYyI2RRzRX9spMWdT73A+n3Pc+dTLyzJI/l1vQ4gWxwjYj6KCPq6Areu1wHs3DLEkw9sZmigHzG1Nv/kA5tzIzYiZlXE0s21Ancxw6/OtfJscYyIThVxRV9X4OZ1ABHRC4oI+roCN2vlEdELigj6ugI3a+UR0QuKWKOv8/0rWSuPiBtdEUEPCdyIiKspYukmIiKuLkEfEVG4BH1EROES9BERhUvQR0QU7oZ7H72k88Bf1V3HdbgNeLPuIpZYznl5WG7n3Kvn+yO2Z/3o9g0X9L1KUvNqL/0vVc55eVhu51zi+WbpJiKicAn6iIjCJei753DdBdQg57w8LLdzLu58s0YfEVG4XNFHRBQuQR8RUbgE/SKQ9JgkS7qt7loWm6QDkv5C0jckfUHSQN01LQZJ2yWNSRqXtK/uehabpDWSviLpFUmjkj5dd01LRVKfpBFJ/7XuWrolQd9lktYAPwm8XnctS+RPgDtsfwj4H8D+muvpOkl9wCHgXmAT8KCkTfVWteguAY/Z3gR8DHh0GZzztE8Dr9ZdRDcl6LvvV4F/DSyLu9y2/9j2par5MrC6znoWyVZg3PYZ2xeAI8COmmtaVLa/bftr1c//h6ngK/6DD5JWA/cB/6nuWropQd9FknYALdtfr7uWmvwL4It1F7EIhoA32tpnWQahN03SOmAL8NWaS1kKv8bUhdrf1lxHVxXzhamlIulLwA/PMvQ54N8wtWxTlGuds+0/qOZ8jqm/7v/uUtYWi0vS+4D/DPyC7bfrrmcxSfoE8B3bJyX9eM3ldFWCfp5s3z1bv6TNwHrg65Jgagnja5K22v6fS1hi113tnKdJ+ufAJ4CfcJkPZrSANW3t1VVf0SStYCrkf9f20brrWQJ3AvdL+ifAe4G/K+l3bP9szXUtWB6YWiSS/hJo2O7Ft+B1TNJ24CDwcdvn665nMUi6iakbzT/BVMCfAB6yPVprYYtIU1crvwX8te1fqLmcJVdd0f+i7U/UXEpXZI0+FurXgVuBP5F0StJv1F1Qt1U3m/cAw0zdlHyu5JCv3An8M+Cu6r/rqepKN3pQrugjIgqXK/qIiMIl6CMiCpegj4goXII+IqJwCfqIiMIl6CMiCpegj4go3P8DDrT00nV6IoIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "x,y, inds = get_batch(1, 100, 1,device)\n",
    "# print(inds)\n",
    "print(inds[0])\n",
    "# print(model(x))\n",
    "# print(y)\n",
    "error_present(nn.Sigmoid()(model(x))[0], inds[0], y[0])\n",
    "print(y)\n",
    "print(nn.Sigmoid()(model(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507698ed-57bf-49d1-9e6e-63fbaf6f6002",
   "metadata": {},
   "source": [
    "Despite literally everything I tried I could not get neither RNNs or LSTMs to actually work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a24f9d0-462e-4613-89c0-e831e8820132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
