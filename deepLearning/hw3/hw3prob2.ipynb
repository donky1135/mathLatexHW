{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dc0e15f-5077-4d32-9504-2018f5540ec1",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc0d5683-32ba-44ad-9881-10bdf3408ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import func3\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b52eced-7bfb-4f15-81f5-e55d6c378945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqGen(n, ratio):\n",
    "    ind = random.sample(range(10), 5)\n",
    "    ind.sort()\n",
    "    randmu = 2*torch.rand((5)) - 1\n",
    "    T = random.randint(0, n)\n",
    "    haspoint = random.random()\n",
    "    seq = torch.randn((n,10))\n",
    "    haschange = False\n",
    "    if haspoint <= ratio:\n",
    "        haschange = True\n",
    "        for t in range(n):\n",
    "                j = 0\n",
    "                for i in range(10):\n",
    "                    if i in ind:\n",
    "                        seq[t][i] = seq[t][i] + randmu[j]\n",
    "                        j = j+1\n",
    "        \n",
    "        \n",
    "        \n",
    "    return seq, ind, randmu, haschange, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d60e1b3a-79a6-47bf-8a3a-f4851b249985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "[1, 2, 6, 7, 8]\n",
      "tensor([-0.9562, -0.3473, -0.9875,  0.1532, -0.2156])\n",
      "0.6161402811144422 32\n",
      "0 tensor([-0.8207,  0.1794,  0.3079,  1.6066, -0.4839, -0.7526, -2.0831,  1.8277,\n",
      "        -0.1502,  0.3111])\n",
      "1 tensor([-0.2142, -1.0767,  0.4379, -0.2036, -0.5312,  0.1712, -1.0970, -0.1783,\n",
      "         0.9725,  1.3602])\n",
      "2 tensor([ 0.5295, -1.6347, -1.7138, -0.1080, -1.4227, -0.2295, -3.5396, -0.7612,\n",
      "        -0.0229, -1.0080])\n",
      "3 tensor([ 0.1370, -2.4191,  0.1669, -0.5856,  1.0850,  0.2412, -2.5732,  0.5730,\n",
      "        -1.6587,  2.1049])\n",
      "4 tensor([ 0.1950, -1.4301,  0.8942, -0.4636,  0.4511, -1.3616, -2.6730, -0.4233,\n",
      "         0.4155, -1.8123])\n",
      "5 tensor([ 0.5021, -1.9498,  1.4541, -0.6365,  0.8206,  1.6822, -0.5846, -1.8780,\n",
      "         0.7893,  1.2262])\n",
      "6 tensor([ 2.2820, -1.8379,  0.4255, -1.2552, -1.9233,  0.0566, -0.8474, -0.0619,\n",
      "        -1.3124, -1.2023])\n",
      "7 tensor([ 0.7467, -1.6236,  1.7891,  0.6751, -1.5157, -0.5240, -1.5478,  0.0749,\n",
      "        -2.2192, -0.0554])\n",
      "8 tensor([-0.3317, -1.1479, -0.6431, -0.8336, -0.4878,  0.9498,  0.3702, -0.3619,\n",
      "        -0.6403, -0.3130])\n",
      "9 tensor([ 0.0427, -0.4701, -0.6875,  0.3156,  0.2483,  0.7862, -1.9295,  1.1453,\n",
      "        -0.4552,  0.9877])\n",
      "10 tensor([-0.7264,  0.4268,  0.2399, -1.6592,  1.3702,  1.1743, -0.7609, -1.7007,\n",
      "        -0.2308,  1.1703])\n",
      "11 tensor([ 1.2963,  0.6202,  0.1879, -0.5501, -1.0581,  1.2883, -0.4384, -0.0068,\n",
      "        -1.8337, -0.2490])\n",
      "12 tensor([ 2.0594, -1.2372, -0.6629,  0.1657, -0.4039,  3.0873, -2.1235,  0.6137,\n",
      "        -1.9270,  0.0258])\n",
      "13 tensor([-0.0512, -1.3514, -1.1828, -0.5195,  1.1534,  0.9828, -0.4848, -0.7895,\n",
      "         0.5263, -0.5963])\n",
      "14 tensor([-0.2038, -1.0236, -0.3511, -0.0525, -0.8279, -0.5609, -1.3086, -1.0568,\n",
      "         0.3962, -0.2257])\n",
      "15 tensor([ 0.2827, -0.7232, -1.7130,  1.0259, -0.1708,  1.1390, -0.0591,  1.4339,\n",
      "        -0.5922, -0.6315])\n",
      "16 tensor([ 0.4259,  0.3105,  0.7577, -1.5364, -0.1309,  1.6462, -3.4684,  0.2698,\n",
      "         0.6937,  0.6036])\n",
      "17 tensor([-0.7802, -1.3054,  0.3520,  0.3999, -0.1299,  0.2365, -3.6587,  1.1396,\n",
      "         1.7791, -0.1453])\n",
      "18 tensor([ 1.5140, -0.7352, -0.2289, -0.1941,  0.9446, -0.6643,  0.2741,  1.1399,\n",
      "        -0.4073,  3.1913])\n",
      "19 tensor([ 1.1461, -1.0141, -1.6668, -0.8688, -0.5514, -1.3027, -0.0328,  0.3790,\n",
      "         0.0600, -0.1807])\n",
      "20 tensor([ 0.3139, -3.3017, -0.5058,  0.8513, -0.1385, -0.7207, -0.0137,  1.1183,\n",
      "         0.0420,  2.1492])\n",
      "21 tensor([ 0.9116, -2.3968,  0.8690,  0.0509, -1.2512, -0.8802,  0.1740, -0.4139,\n",
      "        -0.3949,  0.1696])\n",
      "22 tensor([ 0.1606, -0.1929, -2.0758,  0.0466, -0.1401, -0.0838,  0.0752, -0.8827,\n",
      "         0.3723, -1.7049])\n",
      "23 tensor([ 0.9732, -2.1842, -3.4199,  0.3497, -0.1572,  0.8394, -2.5524,  1.0572,\n",
      "        -1.3296,  1.2638])\n",
      "24 tensor([ 0.7018, -0.4137, -2.0820, -1.8370,  0.2878, -1.7844, -2.6749, -1.0149,\n",
      "         0.6821, -0.7541])\n",
      "25 tensor([-0.0782, -2.2193,  1.0253, -0.0908,  0.7127,  1.4419, -0.7022,  0.7304,\n",
      "        -0.6838,  0.3092])\n",
      "26 tensor([-1.7411, -0.4429,  0.1981, -0.2094, -1.3289, -0.0561, -1.4164,  1.2066,\n",
      "         0.7222,  0.8438])\n",
      "27 tensor([-0.2360,  0.9469, -0.8412,  1.5721,  0.0079,  0.9482,  0.7958,  1.9662,\n",
      "         1.0941, -0.1520])\n",
      "28 tensor([ 0.8370, -0.8091, -1.5732, -0.7584, -1.2109, -1.2792,  1.6737,  1.3435,\n",
      "         1.3263, -0.1695])\n",
      "29 tensor([ 0.1941,  0.4557,  0.1908,  0.2825,  1.4526,  0.2193, -0.6829,  0.1248,\n",
      "        -1.0038,  0.3054])\n",
      "30 tensor([-2.4664, -1.0957,  0.4358, -0.2206,  0.2540, -0.9400, -0.9025,  0.2530,\n",
      "        -0.8123,  2.4073])\n",
      "31 tensor([-0.2226, -0.8222, -2.8959, -0.4822, -0.5269,  0.5505, -3.0565,  0.4287,\n",
      "        -1.9379, -1.2390])\n",
      "32 tensor([ 2.2179, -1.0257,  0.7195, -1.3503, -0.5949, -0.6649,  0.9320, -0.1483,\n",
      "         0.3584,  1.9230])\n",
      "33 tensor([ 0.0172,  0.1460,  0.7817, -1.0988, -0.1113,  0.2191, -0.9100,  1.1506,\n",
      "         0.9552,  0.6159])\n",
      "34 tensor([ 0.2359, -0.5783, -1.0224, -0.7034,  0.4856, -0.7187,  0.0600,  1.7021,\n",
      "        -0.8951,  0.6386])\n",
      "35 tensor([ 1.0481, -0.7586,  1.4140,  0.0232, -2.1374, -2.9923, -0.7614, -1.0918,\n",
      "         1.5403, -1.5160])\n",
      "36 tensor([-2.3617, -0.7438, -1.2293, -0.3397,  1.0523, -0.3216, -1.2497,  2.2440,\n",
      "         0.8689,  0.8730])\n",
      "37 tensor([ 1.1343,  0.0384, -1.2858, -0.1395, -0.3720, -1.3857, -0.5083,  1.2094,\n",
      "         1.8681, -0.3270])\n",
      "38 tensor([ 1.0653, -1.5084, -0.5895, -1.4850, -1.2288,  0.6012, -0.5131,  0.9079,\n",
      "         1.0501,  0.4438])\n",
      "39 tensor([-1.3559, -0.6309, -0.6518, -0.5059,  0.3646,  1.0136, -0.7764,  0.9950,\n",
      "         0.1789, -0.3249])\n",
      "40 tensor([ 0.2897, -0.4734, -0.8220, -1.0959, -1.5107,  0.2487, -1.0132,  0.6972,\n",
      "        -0.4905,  0.4704])\n",
      "41 tensor([-0.3715, -0.7384, -0.3297,  0.4870, -0.2368, -0.7318, -3.8826,  0.4033,\n",
      "         0.0052, -0.0245])\n",
      "42 tensor([-1.3670, -0.8804,  1.2980, -0.7038, -0.9758, -0.6962, -2.4859,  1.7952,\n",
      "        -0.4067,  0.3147])\n",
      "43 tensor([ 1.4550, -0.8964,  1.7744,  1.0458,  0.0460, -1.9887, -0.6888,  1.1571,\n",
      "        -1.0823, -0.7572])\n",
      "44 tensor([ 0.0738, -2.0093, -0.3929, -0.2345,  0.3049,  0.0195, -1.3605, -0.0834,\n",
      "        -1.0030, -0.5915])\n",
      "45 tensor([-0.6067, -1.6855, -0.8935,  1.1589,  0.9653,  0.8151, -1.6615,  1.2381,\n",
      "         0.0158, -0.1603])\n",
      "46 tensor([ 0.8498,  1.8800, -0.6960,  1.0809, -1.5723,  0.8616, -0.4913,  0.8428,\n",
      "        -0.3072,  1.6369])\n",
      "47 tensor([ 0.8448, -1.6795, -1.2136,  0.1681, -0.0153,  0.6089, -1.1625, -1.8104,\n",
      "         0.0280, -0.5815])\n",
      "48 tensor([-1.2901,  0.5179, -1.5240,  0.1285, -0.0227,  0.1577, -0.1523, -1.4001,\n",
      "        -0.1005, -2.0535])\n",
      "49 tensor([-1.3494, -2.0421,  0.5067,  0.4519, -1.7181,  0.2881,  2.3673,  0.6069,\n",
      "        -0.3579,  0.7844])\n"
     ]
    }
   ],
   "source": [
    "seq, ind, randmu, haspoint, T = seqGen(50, 0.8)\n",
    "print(len(seq))\n",
    "print(ind)\n",
    "print(randmu)\n",
    "print(haspoint, T)\n",
    "for i in range(len(seq)):\n",
    "    print(i, seq[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "970e090d-6507-4e44-99cc-4ccad20acd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class changeDetectRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(changeDetectRNN, self).__init__()\n",
    "        self.current_itemf = torch.nn.Linear( in_features = 10, out_features = 100, bias = True )\n",
    "        self.current_itemb = torch.nn.Linear( in_features = 10, out_features = 100, bias = True )\n",
    "\n",
    "        self.prev_itemf1 = torch.nn.Linear( in_features = 100, out_features = 100, bias = False )\n",
    "        self.prev_itemb1 = torch.nn.Linear( in_features = 100, out_features = 100, bias = False )\n",
    "\n",
    "        self.prev_itemf2 = torch.nn.Linear( in_features = 100, out_features = 100, bias = False )\n",
    "        self.prev_itemb2 = torch.nn.Linear( in_features = 100, out_features = 100, bias = False )\n",
    "\n",
    "        self.prev_itemf3 = torch.nn.Linear( in_features = 100, out_features = 100, bias = False )\n",
    "        self.prev_itemb3 = torch.nn.Linear( in_features = 100, out_features = 100, bias = False )\n",
    "\n",
    "        \n",
    "        self.normf = nn.LayerNorm(100)\n",
    "        self.normb = nn.LayerNorm(100)\n",
    "        \n",
    "        self.point_detector = nn.Sequential(nn.Linear(200,1000), nn.LayerNorm(1000),nn.Sigmoid(),nn.Linear(1000,1000),nn.Sigmoid(), nn.LayerNorm(1000), nn.Linear(1000,1),nn.Sigmoid() )\n",
    "    def forward(self, seq):\n",
    "        n = seq.shape[1]\n",
    "        batch_size = seq.shape[0]\n",
    "        seqb = torch.flip(seq, [1])\n",
    "        yf = []\n",
    "        yb = []\n",
    "        yf.append(nn.Sigmoid()(self.normf(self.current_itemf(seq[:,0,:]))))\n",
    "        yb.append(nn.Sigmoid()(self.normb(self.current_itemb(seqb[:,0,:]))))\n",
    "        yf.append(nn.Sigmoid()(self.normf(self.current_itemf(seq[:,1,:])+ self.prev_itemf1(yf[-1]))))\n",
    "        yb.append(nn.Sigmoid()(self.normb(self.current_itemb(seqb[:,1,:])+ self.prev_itemb1(yb[-1]))))\n",
    "        yf.append(nn.Sigmoid()(self.normf(self.current_itemf(seq[:,2,:]) + self.prev_itemf1(yf[-1])+ self.prev_itemf2(yf[-2]))))\n",
    "        yb.append(nn.Sigmoid()(self.normb(self.current_itemb(seqb[:,2,:]) + self.prev_itemb1(yb[-1])+ self.prev_itemb2(yf[-2]))))\n",
    "        for i in range(3,n):\n",
    "            # print(yf[-1].shape)\n",
    "            yf.append(nn.Sigmoid()(self.normf(self.current_itemf(seq[:,i,:]) + self.prev_itemf1(yf[-1])+ self.prev_itemf2(yf[-2])+self.prev_itemf3(yf[-3]))))\n",
    "            yb.append(nn.Sigmoid()(self.normb(self.current_itemb(seqb[:,i,:]) + self.prev_itemb1(yb[-1])+ self.prev_itemb2(yf[-2])+self.prev_itemb3(yf[-3]))))\n",
    "        yb.reverse()\n",
    "\n",
    "        changepoints = torch.zeros((batch_size, n))\n",
    "        \n",
    "        for i in range(n):\n",
    "            \n",
    "            changepoints[:,i] = self.point_detector(torch.cat((yf[i], yb[i]), 1))[:,0]\n",
    "\n",
    "        return changepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b53e87b-0eb1-4a17-ba7a-763d0c86a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class changeDetectLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(changeDetectLSTM, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(10, 10,1,batch_first=True, bidirectional=True)\n",
    "        #  nn.LSTM(10, 20,5,batch_first=True, bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(10, 5,3,batch_first=True)\n",
    "        \n",
    "        self.classifierSimp = nn.Linear(20,1)\n",
    "        \n",
    "        self.classifyLSTM = nn.LSTM(20, 1, 1, batch_first=True)\n",
    "        self.classifier = nn.Sequential(nn.Linear(20,200), nn.ELU(), nn.LayerNorm(200),\n",
    "                                        nn.Linear(200,100), nn.ELU(), nn.LayerNorm(100), nn.Linear(100,1))\n",
    "        self.point_detector = nn.Sequential(nn.Linear(200,1000), nn.LayerNorm(1000),nn.Sigmoid(),nn.Linear(1000,1000),nn.Sigmoid(), nn.LayerNorm(1000), nn.Linear(1000,1),nn.Sigmoid() )\n",
    "\n",
    "    \n",
    "    def forward(self, seq):\n",
    "        # seq = torch.mul(seq, 10)\n",
    "        seq, _ = self.lstm1(seq)\n",
    "        seq, _ = self.classifyLSTM(seq)\n",
    "        \n",
    "        return seq[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd1c174f-88aa-4cff-88a0-705212367651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.4984, -0.3807, -0.4210,  0.1526,  0.1696,  0.4242,  0.7521,  0.1741,\n",
      "         0.8790,  0.4640])\n",
      "tensor([ 1.4984, -0.3807, -0.4210,  0.1526,  0.1696,  0.4242,  0.7521,  0.1741,\n",
      "         0.8790,  0.4640,  1.4984, -0.3807, -0.4210,  0.1526,  0.1696,  0.4242,\n",
      "         0.7521,  0.1741,  0.8790,  0.4640])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10)\n",
    "print(x)\n",
    "print(torch.cat((x,x), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "643802e1-513a-476b-b4f5-72c847387da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size, seq_length, ratio, device):\n",
    "    x_batch = torch.zeros((batch_size, seq_length, 10), device=device)\n",
    "    y_batch = torch.zeros((batch_size, seq_length), device=device)\n",
    "    indices = []\n",
    "    for i in range(batch_size):\n",
    "        seq, _, _, haschange, T = seqGen(seq_length, ratio)\n",
    "        if haschange:\n",
    "            indices.append(T)\n",
    "        else:\n",
    "            indices.append(-1)\n",
    "        for j in range(len(seq)):\n",
    "            if haschange  and j >= T:\n",
    "                y_batch[i][j] = 1\n",
    "            \n",
    "        x_batch[i] = seq\n",
    "    return x_batch, y_batch,indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bc3ec4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch1(x, y, batch_size):\n",
    "    n = x.shape[0]\n",
    "\n",
    "    batch_indices = random.sample( [ i for i in range(n) ], k = batch_size )\n",
    "\n",
    "    x_batch = x[ batch_indices ]\n",
    "    y_batch = y[ batch_indices ]\n",
    "`\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a000aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_present(modeled, T, seq):\n",
    "    values = []\n",
    "    for i in range(11):\n",
    "        if i - 5 + T > 100:\n",
    "            values.append(1.0)\n",
    "        else:\n",
    "            values.append(modeled[i - 5 + T].item())\n",
    "    plt.scatter([i-5 for i in range(11)], values)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f216d060-2593-4691-b7b2-03e8e90fe1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Test loss 225.44598388671875 Training loss 22107.282874405384\n",
      "2 Test loss 225.385986328125 Training loss 21626.872350424528\n",
      "3 Test loss 225.13775634765625 Training loss 21742.12245297432\n",
      "4 Test loss 223.85076904296875 Training loss 21469.17854642868\n",
      "5 Test loss 219.8204803466797 Training loss 21493.120545864105\n",
      "6 Test loss 219.434326171875 Training loss 20848.415479958057\n",
      "7 Test loss 217.42373657226562 Training loss 20106.035157322884\n",
      "8 Test loss 217.7147979736328 Training loss 22339.697484970093\n",
      "9 Test loss 217.67823791503906 Training loss 20481.008216679096\n",
      "10 Test loss 217.2122039794922 Training loss 21250.66894054413\n",
      "11 Test loss 217.86575317382812 Training loss 20101.938264101744\n",
      "12 Test loss 217.00762939453125 Training loss 19986.369026720524\n",
      "13 Test loss 218.21104431152344 Training loss 21334.30103316903\n",
      "14 Test loss 216.85292053222656 Training loss 22547.35741508007\n",
      "15 Test loss 218.88172912597656 Training loss 20473.743572294712\n",
      "16 Test loss 216.77340698242188 Training loss 20180.607003718615\n",
      "17 Test loss 217.63841247558594 Training loss 19648.493882238865\n",
      "18 Test loss 218.72926330566406 Training loss 20005.670599371195\n",
      "19 Test loss 216.73585510253906 Training loss 20817.41113716364\n",
      "20 Test loss 217.62954711914062 Training loss 21844.526859283447\n",
      "21 Test loss 218.7073974609375 Training loss 20162.95820325613\n",
      "22 Test loss 216.84085083007812 Training loss 21394.800533235073\n",
      "23 Test loss 216.936279296875 Training loss 21234.924498438835\n",
      "24 Test loss 218.5790252685547 Training loss 21882.88523185253\n",
      "25 Test loss 217.3185272216797 Training loss 20387.460026174784\n",
      "26 Test loss 216.78285217285156 Training loss 21343.445324897766\n",
      "27 Test loss 217.6390380859375 Training loss 20307.37776389718\n",
      "28 Test loss 218.30343627929688 Training loss 21860.943156778812\n",
      "29 Test loss 216.92916870117188 Training loss 19523.559620976448\n",
      "30 Test loss 216.82896423339844 Training loss 20700.45177036524\n",
      "31 Test loss 217.7481689453125 Training loss 19723.66124165058\n",
      "32 Test loss 218.00953674316406 Training loss 20013.98474892974\n",
      "33 Test loss 216.8868408203125 Training loss 19773.223042726517\n",
      "34 Test loss 216.91644287109375 Training loss 22154.85070580244\n",
      "35 Test loss 217.87185668945312 Training loss 20758.856645405293\n",
      "36 Test loss 217.24220275878906 Training loss 21839.37585169077\n",
      "37 Test loss 216.77590942382812 Training loss 21870.79231825471\n",
      "38 Test loss 217.43125915527344 Training loss 20530.13922047615\n",
      "39 Test loss 218.3489532470703 Training loss 21926.427698135376\n",
      "40 Test loss 217.0413818359375 Training loss 21285.261012792587\n"
     ]
    }
   ],
   "source": [
    "model = changeDetectLSTM()\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "\n",
    "x_test, y_test, _ = get_batch(1000,100, 1, device)\n",
    "for epoch in range(40):\n",
    "    totalLoss = 0\n",
    "    for i in range(2**8):\n",
    "        L = random.randint(2,100)\n",
    "        # L = 10\n",
    "        x_batch, y_batch, _ = get_batch(64, L, 0.8, device=device)\n",
    "        optimizer.zero_grad \n",
    "        # print(y_batch.shape)\n",
    "        output = model.forward(x_batch)\n",
    "        # print(output.shape)\n",
    "        # print(y_batch[0])\n",
    "#         print(output.shape)\n",
    "#         print(y_batch.shape)\n",
    "        loss = torch.nn.CrossEntropyLoss()(output, y_batch)\n",
    "        totalLoss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print((epoch+1),\"Test loss\",torch.nn.CrossEntropyLoss(reduction='mean')(model.forward(x_test), y_test).item(), \"Training loss\", totalLoss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f535e0a0-e311-4f6a-9fb8-9ee6b50ab8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.3699, 0.3188, 0.3181, 0.3271, 0.3338, 0.3392, 0.3433, 0.3481, 0.3532,\n",
      "         0.3576, 0.3642, 0.3698, 0.3775, 0.3840, 0.3909, 0.3979, 0.4050, 0.4124,\n",
      "         0.4200, 0.4281, 0.4370, 0.4466, 0.4552, 0.4675, 0.4768, 0.4881, 0.4967,\n",
      "         0.5066, 0.5166, 0.5268, 0.5371, 0.5471, 0.5586, 0.5721, 0.5826, 0.5923,\n",
      "         0.6010, 0.6106, 0.6189, 0.6302, 0.6381, 0.6455, 0.6530, 0.6603, 0.6681,\n",
      "         0.6738, 0.6790, 0.6841, 0.6885, 0.6933, 0.6976, 0.7011, 0.7041, 0.7070,\n",
      "         0.7096, 0.7121, 0.7140, 0.7163, 0.7186, 0.7200, 0.7214, 0.7225, 0.7234,\n",
      "         0.7243, 0.7250, 0.7257, 0.7264, 0.7270, 0.7276, 0.7281, 0.7285, 0.7288,\n",
      "         0.7291, 0.7294, 0.7297, 0.7299, 0.7301, 0.7302, 0.7304, 0.7305, 0.7306,\n",
      "         0.7307, 0.7307, 0.7308, 0.7308, 0.7309, 0.7309, 0.7309, 0.7310, 0.7310,\n",
      "         0.7310, 0.7310, 0.7310, 0.7310, 0.7310, 0.7310, 0.7310, 0.7310, 0.7310,\n",
      "         0.7310]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "x,y, inds = get_batch(1, 100, 1,device)\n",
    "# print(inds)\n",
    "print(inds[0])\n",
    "# print(model(x))\n",
    "# print(y)\n",
    "error_present(nn.Sigmoid()(model(x))[0], inds[0], y[0])\n",
    "print(y)\n",
    "print(nn.Sigmoid()(model(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a3f3c6a0-36ec-4ba5-bb9d-c22a27fd6839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.0241, -0.0050, -0.0436,  ...,  0.0630, -0.1782,  0.0905],\n",
      "         [-0.0416, -0.0136, -0.0568,  ...,  0.0361, -0.1718,  0.0904],\n",
      "         [-0.0542, -0.0191, -0.0371,  ...,  0.0546, -0.1764,  0.0810],\n",
      "         ...,\n",
      "         [-0.0719, -0.0675, -0.0368,  ...,  0.0970, -0.2168,  0.0861],\n",
      "         [-0.0404, -0.0170, -0.0637,  ...,  0.0535, -0.1707,  0.0789],\n",
      "         [-0.0438, -0.0119, -0.0418,  ...,  0.0529, -0.1878,  0.0725]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward0>), tensor([[[ 0.3606,  0.3763, -0.0703,  ...,  0.4405, -0.0639, -0.0504],\n",
      "         [-0.1602,  0.0735,  0.1989,  ..., -0.1785, -0.3362,  0.3406],\n",
      "         [ 0.3833,  0.1238,  0.0771,  ..., -0.2267,  0.0039,  0.1872],\n",
      "         ...,\n",
      "         [ 0.0477, -0.1614,  0.4257,  ..., -0.1218, -0.0999, -0.2118],\n",
      "         [ 0.2183,  0.1890,  0.2391,  ..., -0.0024, -0.1767,  0.2191],\n",
      "         [ 0.3539,  0.1075, -0.1330,  ...,  0.2023,  0.1865,  0.1567]],\n",
      "\n",
      "        [[ 0.1841, -0.1916,  0.1030,  ..., -0.1199, -0.0565, -0.3316],\n",
      "         [ 0.2708, -0.0513,  0.1375,  ..., -0.0514,  0.0226,  0.0029],\n",
      "         [ 0.2293, -0.1262,  0.0797,  ...,  0.0062,  0.0398, -0.1160],\n",
      "         ...,\n",
      "         [ 0.3206, -0.2211,  0.1171,  ..., -0.0858, -0.2871, -0.0889],\n",
      "         [ 0.2439, -0.1291,  0.1587,  ..., -0.0200,  0.0680, -0.1142],\n",
      "         [ 0.2231, -0.1402,  0.0637,  ..., -0.0234, -0.0695, -0.1595]],\n",
      "\n",
      "        [[ 0.0701,  0.1192,  0.0980,  ...,  0.0359, -0.0475, -0.0033],\n",
      "         [-0.0464, -0.0015,  0.0441,  ...,  0.0048, -0.0827,  0.0074],\n",
      "         [-0.0815,  0.0010, -0.0035,  ..., -0.0254,  0.0032,  0.0539],\n",
      "         ...,\n",
      "         [-0.1808,  0.0359,  0.0187,  ..., -0.0930,  0.0773,  0.1740],\n",
      "         [-0.0752,  0.0244,  0.0567,  ...,  0.0040, -0.0628,  0.0536],\n",
      "         [-0.0180,  0.0627,  0.1131,  ...,  0.0078, -0.0759, -0.0309]],\n",
      "\n",
      "        [[-0.0167,  0.0488, -0.0876,  ...,  0.0214,  0.0788,  0.1387],\n",
      "         [-0.0754, -0.0093, -0.1435,  ..., -0.0124,  0.0448,  0.1228],\n",
      "         [-0.0804, -0.0005, -0.1231,  ..., -0.0592,  0.0351,  0.1422],\n",
      "         ...,\n",
      "         [-0.0053,  0.0070, -0.1649,  ..., -0.0232, -0.0051,  0.0953],\n",
      "         [ 0.0078,  0.0070, -0.1240,  ..., -0.0235,  0.0620,  0.1457],\n",
      "         [-0.0146,  0.0153, -0.0982,  ..., -0.0272,  0.0500,  0.1434]],\n",
      "\n",
      "        [[-0.0241, -0.0050, -0.0436,  ...,  0.0630, -0.1782,  0.0905],\n",
      "         [-0.0416, -0.0136, -0.0568,  ...,  0.0361, -0.1718,  0.0904],\n",
      "         [-0.0542, -0.0191, -0.0371,  ...,  0.0546, -0.1764,  0.0810],\n",
      "         ...,\n",
      "         [-0.0719, -0.0675, -0.0368,  ...,  0.0970, -0.2168,  0.0861],\n",
      "         [-0.0404, -0.0170, -0.0637,  ...,  0.0535, -0.1707,  0.0789],\n",
      "         [-0.0438, -0.0119, -0.0418,  ...,  0.0529, -0.1878,  0.0725]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward0>))\n"
     ]
    }
   ],
   "source": [
    "myRNN= nn.RNN(10,100,5).to(device)\n",
    "print(myRNN(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
