{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dc0e15f-5077-4d32-9504-2018f5540ec1",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc0d5683-32ba-44ad-9881-10bdf3408ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import func3\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b52eced-7bfb-4f15-81f5-e55d6c378945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqGen(n):\n",
    "    ind = random.sample(range(10), 5)\n",
    "    ind.sort()\n",
    "    randmu = 2*torch.rand((5)) - 1\n",
    "    T = random.randint(0, n)\n",
    "    haspoint = random.randint(0,1)\n",
    "    seq = torch.randn((n,10))\n",
    "    for t in range(n):\n",
    "        if t >= T and haspoint == 1:\n",
    "            j = 0\n",
    "            for i in range(10):\n",
    "                if i in ind:\n",
    "                    seq[t][i] = seq[t][i] + randmu[j]\n",
    "                    j = j+1\n",
    "    return seq, ind, randmu, haspoint, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d60e1b3a-79a6-47bf-8a3a-f4851b249985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "[0, 2, 4, 6, 8]\n",
      "tensor([ 0.9979,  0.3047, -0.1415, -0.7205,  0.8178])\n",
      "0 22\n",
      "0 tensor([ 1.0399,  1.1474, -0.9378, -0.3513,  2.3777,  0.2853,  0.2406,  1.6800,\n",
      "         1.3886, -0.0181])\n",
      "1 tensor([ 0.7223,  0.6952,  1.0068,  0.1953, -0.1839,  1.2503,  1.4580, -0.5539,\n",
      "        -0.1916,  0.7588])\n",
      "2 tensor([ 0.6995,  0.1181, -0.2898,  0.8608, -2.6839, -0.1904,  0.7820, -1.0848,\n",
      "        -2.1385,  2.4629])\n",
      "3 tensor([-0.4236,  1.2407,  0.7797,  0.4725,  0.1904, -1.2370, -1.0132, -1.8932,\n",
      "        -0.2487, -0.7997])\n",
      "4 tensor([ 0.3581, -1.5211,  0.0377, -0.2268,  0.2915, -0.2531,  0.5637,  2.4980,\n",
      "         0.6208,  1.2561])\n",
      "5 tensor([-0.6611,  0.0340,  1.2407, -0.6805, -1.2731,  0.7915,  1.3916, -0.2622,\n",
      "        -0.7772, -0.0042])\n",
      "6 tensor([ 0.0613,  0.0961,  0.4298,  1.2918,  1.7247,  0.7117, -1.7152, -0.4974,\n",
      "         1.5140,  0.1750])\n",
      "7 tensor([-0.5678, -0.5550, -1.6377, -1.2251, -1.1410, -0.7413,  1.4224,  1.7350,\n",
      "         1.0121, -0.6490])\n",
      "8 tensor([ 0.4246,  1.7240,  0.1867, -1.0061,  0.8928, -0.4119,  0.0654,  0.0110,\n",
      "        -0.7618,  0.0546])\n",
      "9 tensor([-3.4850,  1.0239,  0.0525,  0.0356, -0.2099,  1.4621, -0.2307, -0.2536,\n",
      "        -0.1989,  1.0919])\n",
      "10 tensor([ 1.2310,  0.6450,  1.4474,  0.0412, -1.3793, -1.4279,  0.1442,  0.1370,\n",
      "        -0.0252,  2.5725])\n",
      "11 tensor([ 0.0978, -1.5332, -0.0769,  0.7746,  0.3927, -1.6831, -2.3808,  1.9574,\n",
      "         1.0087, -1.3730])\n",
      "12 tensor([ 0.4443,  0.9810,  0.7511, -0.5005,  0.3697,  0.8666, -1.3497,  0.2656,\n",
      "         0.0767, -1.0443])\n",
      "13 tensor([ 0.9448, -1.7039,  1.2213,  1.1835, -0.1029, -0.0457,  1.1650,  1.2532,\n",
      "        -0.5624,  1.6390])\n",
      "14 tensor([-0.3080, -0.2323,  0.8279, -0.0164, -0.3784,  1.5913,  0.8285, -2.1262,\n",
      "         0.0540, -0.3468])\n",
      "15 tensor([ 0.2628,  0.5815, -0.1845,  0.5141,  1.0673, -0.5839, -1.0838, -1.1702,\n",
      "         1.8835, -0.2663])\n",
      "16 tensor([ 0.0233,  0.9354,  0.8940, -0.8090,  0.1741, -0.7993,  1.2126, -1.1663,\n",
      "        -1.7599, -0.3273])\n",
      "17 tensor([ 0.3459,  0.7437,  0.4315,  0.6870,  1.2710, -0.6416,  2.0917,  1.7189,\n",
      "         0.7545,  0.8889])\n",
      "18 tensor([-1.3217,  0.2459,  1.1092, -0.3882, -0.9329,  0.3001, -0.3848, -0.1862,\n",
      "         2.0001, -2.2796])\n",
      "19 tensor([-0.5911,  0.7525,  0.8003,  0.0371, -0.7727,  0.4309, -1.0253, -0.4300,\n",
      "         1.4019,  1.3028])\n",
      "20 tensor([-1.1372,  2.7725, -1.4784, -0.5771, -0.4867, -0.5797, -0.6623,  0.1221,\n",
      "         0.9539, -0.7508])\n",
      "21 tensor([-2.4430, -0.8912,  0.3709,  0.3756,  1.0839,  1.6378, -1.2754,  0.8680,\n",
      "         0.4227, -0.8167])\n",
      "22 tensor([-0.1928,  0.7750,  0.6254,  0.0737,  0.2487, -0.2639, -0.9112, -1.6339,\n",
      "        -0.5799,  0.4800])\n",
      "23 tensor([ 0.0128,  0.4076, -2.7953,  1.3257, -1.1029,  0.2328,  0.3116,  1.2437,\n",
      "         1.1438, -0.7163])\n",
      "24 tensor([-0.4680, -0.0812, -1.1438,  0.9842, -0.8587, -0.2989, -1.4548,  1.5547,\n",
      "        -0.0493,  0.7700])\n",
      "25 tensor([ 1.3222, -1.1661,  1.0254, -0.6423,  1.4050,  0.2609, -2.4602, -0.3606,\n",
      "        -0.2875,  1.6216])\n",
      "26 tensor([ 0.3301, -0.3057,  1.8880,  1.9766, -0.3025, -0.7011,  2.3039,  0.3403,\n",
      "        -2.8325, -0.2751])\n",
      "27 tensor([-3.3394, -0.7681, -0.5387, -0.9972, -0.9472,  0.7849,  0.5680,  0.3937,\n",
      "        -0.6864,  0.1503])\n",
      "28 tensor([ 0.3836, -0.8600, -1.3201, -0.0843,  0.4579, -1.1647,  0.0864,  1.7724,\n",
      "        -0.0225, -0.6601])\n",
      "29 tensor([-0.5962,  2.3326,  0.3459,  2.1521, -0.4021, -0.1154, -1.1924, -0.7336,\n",
      "        -0.4151,  0.6423])\n",
      "30 tensor([-1.3462, -0.0467, -0.2946, -0.8408, -0.0378, -0.4516,  0.9719, -0.0632,\n",
      "        -2.3599,  0.1088])\n",
      "31 tensor([-1.3808, -0.6265, -2.2198, -0.7466, -0.8064,  1.6195,  0.4795, -0.8933,\n",
      "        -1.0305,  0.3371])\n",
      "32 tensor([-0.2071, -0.2750,  1.3463,  0.5057,  0.5057,  1.7088, -0.4713, -0.9338,\n",
      "         0.4425,  0.7075])\n",
      "33 tensor([-0.3022, -0.4151, -1.2538, -0.2811,  0.9035,  1.9469,  0.9264,  2.0769,\n",
      "        -0.0207,  1.2934])\n",
      "34 tensor([-0.5056, -0.1177, -0.8862, -0.2565,  0.8992, -0.5398,  0.1721,  1.1388,\n",
      "        -0.8863,  0.9046])\n",
      "35 tensor([ 0.6296, -0.0508,  0.9568,  1.3871, -0.2980, -1.4235, -0.7216, -0.5389,\n",
      "         0.4384, -1.3634])\n",
      "36 tensor([ 0.0854,  2.1100,  0.1462,  2.0486, -1.2220,  1.1035, -1.2186, -0.6578,\n",
      "         0.3447, -0.8080])\n",
      "37 tensor([-0.8112,  0.6651, -0.3141,  0.5644, -0.2792, -0.2065, -0.2461, -0.0923,\n",
      "         2.0538,  1.5521])\n",
      "38 tensor([ 0.5359, -1.6205,  1.9275, -0.2016,  0.0315, -2.2005, -0.3521,  0.0245,\n",
      "        -0.7536, -0.3261])\n",
      "39 tensor([ 0.6756,  2.1922,  0.5280, -1.7459, -0.9751, -0.4956,  1.5588,  0.4567,\n",
      "         1.8497,  1.6864])\n",
      "40 tensor([ 2.2270,  1.2509, -0.5239,  0.1714, -0.7787,  1.8655,  0.1576, -0.2600,\n",
      "         0.4461, -0.8544])\n",
      "41 tensor([-0.5110, -0.0225,  0.6728,  0.6065,  0.9687,  1.5616, -1.4822,  0.5738,\n",
      "         0.3719, -0.3526])\n",
      "42 tensor([ 0.6539, -1.5806,  0.0272,  1.4182, -1.5754, -0.1381,  0.5825,  0.2775,\n",
      "        -1.6816, -1.8394])\n",
      "43 tensor([ 0.2617,  0.4714, -0.3214, -2.7526,  1.6830,  0.6466, -0.2898, -0.5977,\n",
      "         0.8372,  0.1730])\n",
      "44 tensor([-0.3856, -0.2051,  0.3448,  0.6705,  0.1499,  1.5503, -1.2850, -2.4768,\n",
      "        -1.0213,  0.0474])\n",
      "45 tensor([-0.6694,  0.5230, -0.1546, -0.7847, -1.1734,  1.1982,  0.4057,  0.8674,\n",
      "        -1.0942, -0.3734])\n",
      "46 tensor([-1.2037,  0.4583,  0.8118,  0.4198,  2.1297, -0.5274,  0.9077,  0.1264,\n",
      "         0.0981,  0.9496])\n",
      "47 tensor([ 2.9236, -1.2995, -0.2796,  1.5694, -0.8999,  0.5589, -0.8785, -0.4474,\n",
      "        -0.4976,  1.3619])\n",
      "48 tensor([ 0.2991, -1.5713, -1.0134, -0.2839, -1.3419,  1.0406,  0.4322, -0.2381,\n",
      "         0.0531,  0.4823])\n",
      "49 tensor([-0.5526, -0.6126, -0.1328,  0.6681, -1.0024, -0.4282, -0.3148,  0.1347,\n",
      "         1.0339, -1.1245])\n"
     ]
    }
   ],
   "source": [
    "seq, ind, randmu, haspoint, T = seqGen(50)\n",
    "print(len(seq))\n",
    "print(ind)\n",
    "print(randmu)\n",
    "print(haspoint, T)\n",
    "for i in range(len(seq)):\n",
    "    print(i, seq[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "970e090d-6507-4e44-99cc-4ccad20acd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class changeDetectRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(changeDetectRNN, self).__init__()\n",
    "        self.current_itemf = torch.nn.Linear( in_features = 10, out_features = 100, bias = True )\n",
    "        self.current_itemb = torch.nn.Linear( in_features = 10, out_features = 100, bias = True )\n",
    "\n",
    "        self.prev_itemf1 = torch.nn.Linear( in_features = 100, out_features = 100, bias = False )\n",
    "        self.prev_itemb1 = torch.nn.Linear( in_features = 100, out_features = 100, bias = False )\n",
    "\n",
    "        self.prev_itemf2 = torch.nn.Linear( in_features = 100, out_features = 100, bias = False )\n",
    "        self.prev_itemb2 = torch.nn.Linear( in_features = 100, out_features = 100, bias = False )\n",
    "\n",
    "        self.prev_itemf3 = torch.nn.Linear( in_features = 100, out_features = 100, bias = False )\n",
    "        self.prev_itemb3 = torch.nn.Linear( in_features = 100, out_features = 100, bias = False )\n",
    "\n",
    "        \n",
    "        self.normf = nn.LayerNorm(100)\n",
    "        self.normb = nn.LayerNorm(100)\n",
    "        \n",
    "        self.point_detector = nn.Sequential(nn.Linear(200,1000), nn.LayerNorm(1000),nn.Sigmoid(),nn.Linear(1000,1000),nn.Sigmoid(), nn.LayerNorm(1000), nn.Linear(1000,1),nn.Sigmoid() )\n",
    "    def forward(self, seq):\n",
    "        n = seq.shape[1]\n",
    "        batch_size = seq.shape[0]\n",
    "        seqb = torch.flip(seq, [1])\n",
    "        yf = []\n",
    "        yb = []\n",
    "        yf.append(nn.Sigmoid()(self.normf(self.current_itemf(seq[:,0,:]))))\n",
    "        yb.append(nn.Sigmoid()(self.normb(self.current_itemb(seqb[:,0,:]))))\n",
    "        yf.append(nn.Sigmoid()(self.normf(self.current_itemf(seq[:,1,:])+ self.prev_itemf1(yf[-1]))))\n",
    "        yb.append(nn.Sigmoid()(self.normb(self.current_itemb(seqb[:,1,:])+ self.prev_itemb1(yb[-1]))))\n",
    "        yf.append(nn.Sigmoid()(self.normf(self.current_itemf(seq[:,2,:]) + self.prev_itemf1(yf[-1])+ self.prev_itemf2(yf[-2]))))\n",
    "        yb.append(nn.Sigmoid()(self.normb(self.current_itemb(seqb[:,2,:]) + self.prev_itemb1(yb[-1])+ self.prev_itemb2(yf[-2]))))\n",
    "        for i in range(3,n):\n",
    "            # print(yf[-1].shape)\n",
    "            yf.append(nn.Sigmoid()(self.normf(self.current_itemf(seq[:,i,:]) + self.prev_itemf1(yf[-1])+ self.prev_itemf2(yf[-2])+self.prev_itemf3(yf[-3]))))\n",
    "            yb.append(nn.Sigmoid()(self.normb(self.current_itemb(seqb[:,i,:]) + self.prev_itemb1(yb[-1])+ self.prev_itemb2(yf[-2])+self.prev_itemb3(yf[-3]))))\n",
    "        yb.reverse()\n",
    "\n",
    "        changepoints = torch.zeros((batch_size, n))\n",
    "        \n",
    "        for i in range(n):\n",
    "            \n",
    "            changepoints[:,i] = self.point_detector(torch.cat((yf[i], yb[i]), 1))[:,0]\n",
    "\n",
    "        return changepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "0b53e87b-0eb1-4a17-ba7a-763d0c86a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class changeDetectLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(changeDetectLSTM, self).__init__()\n",
    "        self.lstm1 = nn.RNN(10, 10,2,batch_first=True, bidirectional=True, dropout=0.5)\n",
    "        #  nn.LSTM(10, 20,5,batch_first=True, bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(10, 5,3,batch_first=True)\n",
    "\n",
    "        self.classifyLSTM = nn.LSTM(100, 1, 1, batch_first=True)\n",
    "        self.classifier = nn.Sequential(nn.Linear(20,200), nn.ELU(), nn.LayerNorm(200),\n",
    "                                        nn.Linear(200,200), nn.ELU(), nn.LayerNorm(200),\n",
    "                                        nn.Linear(200,100), nn.ELU(), nn.LayerNorm(100), nn.Linear(100,1))\n",
    "        self.point_detector = nn.Sequential(nn.Linear(200,1000), nn.LayerNorm(1000),nn.Sigmoid(),nn.Linear(1000,1000),nn.Sigmoid(), nn.LayerNorm(1000), nn.Linear(1000,1),nn.Sigmoid() )\n",
    "\n",
    "    \n",
    "    def forward(self, seq):\n",
    "        # seq = torch.mul(seq, 10)\n",
    "        seq, _ = self.lstm1(seq)\n",
    "        seq = self.classifier(seq)\n",
    "        \n",
    "        return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd1c174f-88aa-4cff-88a0-705212367651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.4984, -0.3807, -0.4210,  0.1526,  0.1696,  0.4242,  0.7521,  0.1741,\n",
      "         0.8790,  0.4640])\n",
      "tensor([ 1.4984, -0.3807, -0.4210,  0.1526,  0.1696,  0.4242,  0.7521,  0.1741,\n",
      "         0.8790,  0.4640,  1.4984, -0.3807, -0.4210,  0.1526,  0.1696,  0.4242,\n",
      "         0.7521,  0.1741,  0.8790,  0.4640])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10)\n",
    "print(x)\n",
    "print(torch.cat((x,x), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "643802e1-513a-476b-b4f5-72c847387da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size, seq_length, device):\n",
    "    x_batch = torch.zeros((batch_size, seq_length, 10), device=device)\n",
    "    y_batch = torch.zeros((batch_size, seq_length), device=device)\n",
    "    for i in range(batch_size):\n",
    "        seq, _, _, haspoint, T = seqGen(seq_length)\n",
    "        for j in range(len(seq)):\n",
    "            if haspoint == 1 and j >= T:\n",
    "                y_batch[i][j] = 1\n",
    "            \n",
    "        x_batch[i] = seq\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "168718aa-ea50-4c9a-b028-ca7e13e3e689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.4049, -0.8837,  0.2189,  0.2833,  0.0850, -1.1273, -0.5754,\n",
      "           0.3827,  0.4344, -0.8288],\n",
      "         [-1.0201, -0.6424, -0.3385, -0.1234, -0.4842, -1.3048, -0.5308,\n",
      "           1.0170,  0.7136,  1.6644],\n",
      "         [ 1.3211,  0.5331, -1.3790,  0.1452, -0.2916,  0.6121, -0.3462,\n",
      "          -1.4847,  1.1317, -0.2574],\n",
      "         [-2.4638, -1.2155, -1.1739, -1.5042,  1.0520,  0.7329,  0.4771,\n",
      "          -0.0115,  0.6189, -0.6080],\n",
      "         [-0.5209,  0.4390, -0.3737,  1.7966, -0.9788,  0.2802, -1.2945,\n",
      "          -1.8794, -1.3292, -0.3854],\n",
      "         [-0.3010,  1.3106, -0.8410, -1.0394, -0.6550,  0.9290,  0.7821,\n",
      "           0.5405,  0.3706,  0.8595],\n",
      "         [-0.7153,  1.0079, -0.0314, -1.0289, -2.5729, -0.9301,  1.1003,\n",
      "           1.5781, -0.8748, -1.3504],\n",
      "         [ 0.2485, -0.7091,  0.9974,  2.6215, -0.8839, -1.7273,  0.4768,\n",
      "           0.5396, -0.7275,  0.0954],\n",
      "         [ 0.5676,  0.8866, -0.3271,  1.1786,  0.2498, -1.3037, -1.3073,\n",
      "          -0.7880,  1.5421,  1.2406],\n",
      "         [-0.8465, -0.6530,  0.2417,  0.9759,  0.7215, -0.6293,  0.1233,\n",
      "          -0.6986,  0.6075,  0.3477]]])\n",
      "tensor([[[-0.8465, -0.6530,  0.2417,  0.9759,  0.7215, -0.6293,  0.1233,\n",
      "          -0.6986,  0.6075,  0.3477],\n",
      "         [ 0.5676,  0.8866, -0.3271,  1.1786,  0.2498, -1.3037, -1.3073,\n",
      "          -0.7880,  1.5421,  1.2406],\n",
      "         [ 0.2485, -0.7091,  0.9974,  2.6215, -0.8839, -1.7273,  0.4768,\n",
      "           0.5396, -0.7275,  0.0954],\n",
      "         [-0.7153,  1.0079, -0.0314, -1.0289, -2.5729, -0.9301,  1.1003,\n",
      "           1.5781, -0.8748, -1.3504],\n",
      "         [-0.3010,  1.3106, -0.8410, -1.0394, -0.6550,  0.9290,  0.7821,\n",
      "           0.5405,  0.3706,  0.8595],\n",
      "         [-0.5209,  0.4390, -0.3737,  1.7966, -0.9788,  0.2802, -1.2945,\n",
      "          -1.8794, -1.3292, -0.3854],\n",
      "         [-2.4638, -1.2155, -1.1739, -1.5042,  1.0520,  0.7329,  0.4771,\n",
      "          -0.0115,  0.6189, -0.6080],\n",
      "         [ 1.3211,  0.5331, -1.3790,  0.1452, -0.2916,  0.6121, -0.3462,\n",
      "          -1.4847,  1.1317, -0.2574],\n",
      "         [-1.0201, -0.6424, -0.3385, -0.1234, -0.4842, -1.3048, -0.5308,\n",
      "           1.0170,  0.7136,  1.6644],\n",
      "         [-1.4049, -0.8837,  0.2189,  0.2833,  0.0850, -1.1273, -0.5754,\n",
      "           0.3827,  0.4344, -0.8288]]])\n"
     ]
    }
   ],
   "source": [
    "tensor, _ = get_batch(1,10)\n",
    "print(tensor)\n",
    "print(torch.flip(tensor, [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63f95f24-ac8d-443b-8b6d-7e8735ad76e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossfunc(predictions, actual_labels):\n",
    "    return torch.mean( -1 * torch.log( predictions + 0.0001 ).to(device) * actual_labels - torch.log( 1 - predictions + 0.0001 ) * (1 - actual_labels ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "f216d060-2593-4691-b7b2-03e8e90fe1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Test loss 120.90019226074219 Training loss 3319.4312152266502\n",
      "2 Test loss 120.85693359375 Training loss 3352.4199907183647\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[408], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m L \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# L = 10\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m x_batch, y_batch \u001b[38;5;241m=\u001b[39m \u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad \n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# print(y_batch.shape)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m, in \u001b[0;36mget_batch\u001b[1;34m(batch_size, seq_length, device)\u001b[0m\n\u001b[0;32m      3\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((batch_size, seq_length), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[1;32m----> 5\u001b[0m     seq, _, _, haspoint, T \u001b[38;5;241m=\u001b[39m \u001b[43mseqGen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(seq)):\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m haspoint \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m j \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m T:\n",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m, in \u001b[0;36mseqGen\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m      2\u001b[0m ind \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m), \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      3\u001b[0m ind\u001b[38;5;241m.\u001b[39msort()\n\u001b[1;32m----> 4\u001b[0m randmu \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      5\u001b[0m T \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, n)\n\u001b[0;32m      6\u001b[0m haspoint \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = changeDetectLSTM()\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "x_test, y_test = get_batch(1000,100, device)\n",
    "for epoch in range(40):\n",
    "    totalLoss = 0\n",
    "    for i in range(2**6):\n",
    "        L = random.randint(2,100)\n",
    "        # L = 10\n",
    "        x_batch, y_batch = get_batch(64, L, device)\n",
    "        optimizer.zero_grad \n",
    "        # print(y_batch.shape)\n",
    "        output = model.forward(x_batch)\n",
    "        # print(output.shape)\n",
    "        # print(y_batch[0])\n",
    "        loss = torch.nn.CrossEntropyLoss()(output[:,:,0], y_batch)\n",
    "        totalLoss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print((epoch+1),\"Test loss\",torch.nn.CrossEntropyLoss(reduction='mean')(model.forward(x_test)[:,:,0], y_test).item(), \"Training loss\", totalLoss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "f535e0a0-e311-4f6a-9fb8-9ee6b50ab8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[0.4496, 0.4573, 0.4482, 0.4603, 0.4501, 0.4457, 0.4735, 0.4493, 0.4499,\n",
      "         0.4462, 0.4667, 0.4605, 0.4568, 0.4503, 0.4508, 0.4518, 0.4530, 0.4488,\n",
      "         0.4455, 0.4598, 0.4500, 0.4536, 0.4507, 0.4546, 0.4557, 0.4551, 0.4547,\n",
      "         0.4457, 0.4531, 0.4715, 0.4490, 0.4602, 0.4655, 0.4741, 0.4515, 0.4493,\n",
      "         0.4499, 0.4487, 0.4497, 0.4657, 0.4456, 0.4536, 0.4477, 0.4480, 0.4515,\n",
      "         0.4512, 0.4563, 0.4589, 0.4612, 0.4540, 0.4516, 0.4630, 0.4500, 0.4604,\n",
      "         0.4485, 0.4584, 0.4536, 0.4673, 0.4506, 0.4662, 0.4581, 0.4498, 0.4524,\n",
      "         0.4471, 0.4465, 0.4519, 0.4554, 0.4602, 0.4609, 0.4478, 0.4521, 0.4497,\n",
      "         0.4630, 0.4451, 0.4699, 0.4676, 0.4541, 0.4525, 0.4498, 0.4703, 0.4499,\n",
      "         0.4476, 0.4680, 0.4419, 0.4545, 0.4545, 0.4558, 0.4552, 0.4516, 0.4544,\n",
      "         0.4580, 0.4531, 0.4533, 0.4496, 0.4563, 0.4528, 0.4444, 0.4665, 0.4579,\n",
      "         0.4610]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x,y = get_batch(1, 100, device)\n",
    "print(y)\n",
    "print(nn.Sigmoid()(model(x)[:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a3f3c6a0-36ec-4ba5-bb9d-c22a27fd6839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.0241, -0.0050, -0.0436,  ...,  0.0630, -0.1782,  0.0905],\n",
      "         [-0.0416, -0.0136, -0.0568,  ...,  0.0361, -0.1718,  0.0904],\n",
      "         [-0.0542, -0.0191, -0.0371,  ...,  0.0546, -0.1764,  0.0810],\n",
      "         ...,\n",
      "         [-0.0719, -0.0675, -0.0368,  ...,  0.0970, -0.2168,  0.0861],\n",
      "         [-0.0404, -0.0170, -0.0637,  ...,  0.0535, -0.1707,  0.0789],\n",
      "         [-0.0438, -0.0119, -0.0418,  ...,  0.0529, -0.1878,  0.0725]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward0>), tensor([[[ 0.3606,  0.3763, -0.0703,  ...,  0.4405, -0.0639, -0.0504],\n",
      "         [-0.1602,  0.0735,  0.1989,  ..., -0.1785, -0.3362,  0.3406],\n",
      "         [ 0.3833,  0.1238,  0.0771,  ..., -0.2267,  0.0039,  0.1872],\n",
      "         ...,\n",
      "         [ 0.0477, -0.1614,  0.4257,  ..., -0.1218, -0.0999, -0.2118],\n",
      "         [ 0.2183,  0.1890,  0.2391,  ..., -0.0024, -0.1767,  0.2191],\n",
      "         [ 0.3539,  0.1075, -0.1330,  ...,  0.2023,  0.1865,  0.1567]],\n",
      "\n",
      "        [[ 0.1841, -0.1916,  0.1030,  ..., -0.1199, -0.0565, -0.3316],\n",
      "         [ 0.2708, -0.0513,  0.1375,  ..., -0.0514,  0.0226,  0.0029],\n",
      "         [ 0.2293, -0.1262,  0.0797,  ...,  0.0062,  0.0398, -0.1160],\n",
      "         ...,\n",
      "         [ 0.3206, -0.2211,  0.1171,  ..., -0.0858, -0.2871, -0.0889],\n",
      "         [ 0.2439, -0.1291,  0.1587,  ..., -0.0200,  0.0680, -0.1142],\n",
      "         [ 0.2231, -0.1402,  0.0637,  ..., -0.0234, -0.0695, -0.1595]],\n",
      "\n",
      "        [[ 0.0701,  0.1192,  0.0980,  ...,  0.0359, -0.0475, -0.0033],\n",
      "         [-0.0464, -0.0015,  0.0441,  ...,  0.0048, -0.0827,  0.0074],\n",
      "         [-0.0815,  0.0010, -0.0035,  ..., -0.0254,  0.0032,  0.0539],\n",
      "         ...,\n",
      "         [-0.1808,  0.0359,  0.0187,  ..., -0.0930,  0.0773,  0.1740],\n",
      "         [-0.0752,  0.0244,  0.0567,  ...,  0.0040, -0.0628,  0.0536],\n",
      "         [-0.0180,  0.0627,  0.1131,  ...,  0.0078, -0.0759, -0.0309]],\n",
      "\n",
      "        [[-0.0167,  0.0488, -0.0876,  ...,  0.0214,  0.0788,  0.1387],\n",
      "         [-0.0754, -0.0093, -0.1435,  ..., -0.0124,  0.0448,  0.1228],\n",
      "         [-0.0804, -0.0005, -0.1231,  ..., -0.0592,  0.0351,  0.1422],\n",
      "         ...,\n",
      "         [-0.0053,  0.0070, -0.1649,  ..., -0.0232, -0.0051,  0.0953],\n",
      "         [ 0.0078,  0.0070, -0.1240,  ..., -0.0235,  0.0620,  0.1457],\n",
      "         [-0.0146,  0.0153, -0.0982,  ..., -0.0272,  0.0500,  0.1434]],\n",
      "\n",
      "        [[-0.0241, -0.0050, -0.0436,  ...,  0.0630, -0.1782,  0.0905],\n",
      "         [-0.0416, -0.0136, -0.0568,  ...,  0.0361, -0.1718,  0.0904],\n",
      "         [-0.0542, -0.0191, -0.0371,  ...,  0.0546, -0.1764,  0.0810],\n",
      "         ...,\n",
      "         [-0.0719, -0.0675, -0.0368,  ...,  0.0970, -0.2168,  0.0861],\n",
      "         [-0.0404, -0.0170, -0.0637,  ...,  0.0535, -0.1707,  0.0789],\n",
      "         [-0.0438, -0.0119, -0.0418,  ...,  0.0529, -0.1878,  0.0725]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward0>))\n"
     ]
    }
   ],
   "source": [
    "myRNN= nn.RNN(10,100,5).to(device)\n",
    "print(myRNN(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
