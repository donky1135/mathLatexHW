{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc3e0ff4-4abb-4886-9352-c87e646d8e84",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ab47683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\algeria\\AppData\\Local\\Temp/ipykernel_19480/1058373251.py:14: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  nums = torch.Tensor(np.array([i for i in range(10)], dtype=np.long))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import func3\n",
    "\n",
    "nums = torch.Tensor(np.array([i for i in range(10)], dtype=np.long))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1322def1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(nums.shape)\n",
    "print(nums[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23cc9611",
   "metadata": {},
   "outputs": [],
   "source": [
    "class callAndResponse(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(callAndResponse, self).__init__()\n",
    "        self.sumRNN = nn.RNN(2,15)\n",
    "        self.queryS = nn.ModuleList([nn.Sequential(nn.Linear(15,1)) for i in range(10)]) \n",
    "        self.embedNum = nn.Embedding(10,2)\n",
    "    def summary(self, emseq):\n",
    "        summar, _ = self.sumRNN(emseq)\n",
    "        return summar\n",
    "    def query(self, summar, q):\n",
    "        return self.quertyS[q](summar)\n",
    "    def embed(self, seq):\n",
    "        return embedNum(seq)\n",
    "    \n",
    "    def forward(self, rawseq):\n",
    "        finalOut = torch.zeros((10, rawseq.shape[0]))\n",
    "        summar = self.summary(self.embedNum())\n",
    "        for i in range(10):\n",
    "            finalOut[i] = self.query(summar)\n",
    "        return finalOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb088ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genSeq(n,numterm):\n",
    "    seq = torch.zeros((n))\n",
    "    alphabet = nums[random.sample([i for i in range(10)], k=numterm)]\n",
    "    for i in range(n):\n",
    "        samp = random.randint(0,numterm - 1)\n",
    "        seq[i] = alphabet[samp]\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8a00c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 2., 3., 3., 5., 5., 2., 1., 2., 1., 1., 3., 9., 2., 3., 9., 2., 2.,\n",
      "        5., 9.])\n"
     ]
    }
   ],
   "source": [
    "print(genSeq(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79a0e1ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_19480/1875596891.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\algeria\\AppData\\Local\\Temp/ipykernel_19480/1875596891.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def get_batch\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_batch(batch_size, n, numterm):\n",
    "    batch = torch.zeros((batch_size, n))\n",
    "    for i in range(batch_size):\n",
    "        batch[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
