{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91bd7ef4",
   "metadata": {},
   "source": [
    "# Problem 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96d3d81",
   "metadata": {},
   "source": [
    "Note for no layers, we have 784 inputs going to 10 outputs, and we assume a bias term per each.  This will yield \n",
    "$10 \\cdot 784 $ parameters, as we have each pixel weighted, and 10 outputs, with a further 10 bias terms, one for each \n",
    "output node.  Therefore there is a total of $7840 + 10 = 7850$ parameters when we don't include a hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf20ebc",
   "metadata": {},
   "source": [
    "If a model has $k$ hidden layers with $m$ nodes a piece we have the following calculation: For the first layer we have $784m + m$ parameters for intaking from the image to the first layer.  For the next $k-1$ layers, for each layer we have $m^2$ \n",
    "interconnects, and $m$ bias terms yielding $(k-1)(m^2 + m)$ parameters.  Finally we have $10m$ connections into the output layer, with an additionally $10$ bias.  Therefore, $$Params(m,k) = 784m + m + (k-1)(m^2 + m) + 10(m+1)$$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476809af",
   "metadata": {},
   "source": [
    "# Problem 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fda411",
   "metadata": {},
   "source": [
    "For a given number of parameters P, we have the equation $784m + m + (k-1)(m^2 + m) + 10(m+1) = P.$  We can rearrange the equation to find that $k = \\frac{P-10}{m(m+1)} - \\frac{795}{m+1} + 1$.  In order to maximize/minimize the function \n",
    "we can take the m derivative, and set the numerator of the fraction equal to zero.  In this scenerio \n",
    "we have to solve the equation $0=-795m^2 + 2(P-10)m + (P-10)$.  This has the resulting $m$ values of \n",
    "$$ m = \\frac{1}{795} \\left(P-10 \\pm \\sqrt{(P-10)^2+795(P-10)} \\right) $$.  Note that for sufficently large $P$ that \n",
    "the square root will always be positive, thus we will always have two roots, a maximum and a minimum.  However, \n",
    "for the smaller of the two roots, the limit approaches -0.5, and since we know that by our model we have to have at least 1 parameter per layer implies that solving for $m=1$ will yield $k_p$.  For the smallest $k$, we know for the smaller root $m_b$ that $\\lim_{P \\to \\infty} k(m_b) = -1$.  Thus \n",
    "the smallest possible $k$ would have to be $k=1$.  Note that if $k_p$ is not an integer then one should round $k_p$ down since $m$ is already the \n",
    "correct integer of 1 then the actual number of used parameters falls \"under budget\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6968830-b954-40a9-8bd6-c5deeecafa28",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Problem 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "35bb12e6-a7f1-42ff-ba7e-b4b488405a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_num(k,P):\n",
    "    if k == 1:\n",
    "        return (P-10) // 795\n",
    "    else:\n",
    "        return (int)(math.sqrt((794+k)**2 + 4*(P-10)*(k-1)))// (2*(k-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc31a06f-7666-4878-b682-973212477a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff1ecff4-a10c-451e-9e1f-ee0971a4bedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9.9%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100.0%\n",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0368690e-6fb3-411e-8894-545bfd8a6c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = torch.Tensor( testset.data ) / 256.0 - 0.5\n",
    "test_x = test_x.to(device)\n",
    "test_y = torch.Tensor( testset.targets ).long()\n",
    "test_y = test_y.to(device)\n",
    "train_x = torch.Tensor( trainset.data ) / 256.0 - 0.5\n",
    "train_x = train_x.to(device)\n",
    "train_y = torch.Tensor( trainset.targets ).long()\n",
    "train_y = train_y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b6377a8-1311-4d31-b15c-7086f4b5fcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x, y, batch_size):\n",
    "    n = x.shape[0]\n",
    "\n",
    "    batch_indices = random.sample( [ i for i in range(n) ], k = batch_size )\n",
    "\n",
    "    x_batch = x[ batch_indices ]\n",
    "    y_batch = y[ batch_indices ]\n",
    "\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf9c2d23-6de6-490a-95bd-f0be6ae05d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class layerTesting(nn.Module):\n",
    "    def __init__(self,k,m):\n",
    "        super(layerTesting, self).__init__()\n",
    "\n",
    "        self.layer_input = torch.nn.Linear( in_features = 28*28*1, out_features = m, bias=True )\n",
    "        self.layer_output = torch.nn.Linear( in_features = m, out_features = 10, bias=True )\n",
    "        self.linears = nn.ModuleList([nn.Linear(layers_size, layers_size) for i in range(k-1)])\n",
    "        self.normalize = nn.LayerNorm(m)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        output = nn.Flatten()( input_tensor )\n",
    "        output = self.layer_input(output)\n",
    "        output = nn.ReLU()(output)\n",
    "        output = self.normalize(output)\n",
    "        for l in self.linears:\n",
    "            output = l(output)\n",
    "            output = nn.ReLU()(output)\n",
    "            output = self.normalize(output)\n",
    "        output = self.layer_output(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fe7c3f7-4edc-4a5b-8971-939e11f90c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix( model, x, y ):\n",
    "    identification_counts = np.zeros( shape = (10,10), dtype = np.int32 )\n",
    "    \n",
    "    logits = model.forward( x )\n",
    "    predicted_classes = torch.argmax( logits, dim = 1 )\n",
    "\n",
    "    n = x.shape[0]\n",
    "\n",
    "    for i in range(n):\n",
    "        actual_class = int( y[i].item() )\n",
    "        predicted_class = predicted_classes[i].item()\n",
    "        identification_counts[actual_class, predicted_class] += 1\n",
    "\n",
    "    return identification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "38314cfa-ace0-4c98-baa0-0351c8bf4ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299.0\n",
      "Initial Confusion Matrix\n",
      "[[  9  47 415   0   3 147   4   0 355   0]\n",
      " [ 49 837 135   0   0 112   0   0   1   1]\n",
      " [ 33 218 315   0  32  98  93   0 228  15]\n",
      " [  5 271 318   2  11 252  13   0 136   2]\n",
      " [  0 322 486   1   0  13   0   4 126  30]\n",
      " [  1 306 293   0   4  59   6   4 213   6]\n",
      " [  3 137 389   0   8  50   0   0 362   9]\n",
      " [  0 500 281   0   0  90   0   0 157   0]\n",
      " [  2 309 176   0   5 158  15   4 292  13]\n",
      " [  0 321 487   1   0  17   0   5 157  21]]\n"
     ]
    }
   ],
   "source": [
    "print(m_num(3,100000))\n",
    "model = layerTesting(1,m_num(1,100000))\n",
    "model.to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Initial Confusion Matrix\")\n",
    "print( confusion_matrix( model, test_x, test_y ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677a42ba-7796-46f7-998d-919f6ba121e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
