{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91bd7ef4",
   "metadata": {},
   "source": [
    "# Problem 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96d3d81",
   "metadata": {},
   "source": [
    "Note for no layers, we have 784 inputs going to 10 outputs, and we assume a bias term per each.  This will yield \n",
    "$10 \\cdot 784 $ parameters, as we have each pixel weighted, and 10 outputs, with a further 10 bias terms, one for each \n",
    "output node.  Therefore there is a total of $7840 + 10 = 7850$ parameters when we don't include a hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf20ebc",
   "metadata": {},
   "source": [
    "If a model has $k$ hidden layers with $m$ nodes a piece we have the following calculation: For the first layer we have $784m + m$ parameters for intaking from the image to the first layer.  For the next $k-1$ layers, for each layer we have $m^2$ \n",
    "interconnects, and $m$ bias terms yielding $(k-1)(m^2 + m)$ parameters.  Finally we have $10m$ connections into the output layer, with an additionally $10$ bias.  Therefore, $$Params(m,k) = 784m + m + (k-1)(m^2 + m) + 10(m+1)$$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476809af",
   "metadata": {},
   "source": [
    "# Problem 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fda411",
   "metadata": {},
   "source": [
    "For a given number of parameters P, we have the equation $784m + m + (k-1)(m^2 + m) + 10(m+1) = P.$  We can rearrange the equation to find that $k = \\frac{P-10}{m(m+1)} - \\frac{795}{m+1} + 1$.  In order to maximize/minimize the function \n",
    "we can take the m derivative, and set the numerator of the fraction equal to zero.  In this scenerio \n",
    "we have to solve the equation $0=-795m^2 + 2(P-10)m + (P-10)$.  This has the resulting $m$ values of \n",
    "$$ m = \\frac{1}{795} \\left(P-10 \\pm \\sqrt{(P-10)^2+795(P-10)} \\right) $$.  Note that for sufficently large $P$ that \n",
    "the square root will always be positive, thus we will always have two roots, a maximum and a minimum.  However, \n",
    "for the smaller of the two roots, the limit approaches -0.5, and since we know that by our model we have to have at least 1 parameter per layer implies that solving for $m=1$ will yield $k_p$.  For the smallest $k$, we know for the smaller root $m_b$ that $\\lim_{P \\to \\infty} k(m_b) = -1$.  Thus \n",
    "the smallest possible $k$ would have to be $k=1$.  Note that if $k_p$ is not an integer then one should round $k_p$ down since $m$ is already the \n",
    "correct integer of 1 then the actual number of used parameters falls \"under budget\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6968830-b954-40a9-8bd6-c5deeecafa28",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Problem 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35bb12e6-a7f1-42ff-ba7e-b4b488405a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_num(k,P):\n",
    "    if k == 1:\n",
    "        return (P-10) // 795\n",
    "    else:\n",
    "        return (int)(math.sqrt((794+k)**2 + 4*(P-10)*(k-1)))// (2*(k-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc31a06f-7666-4878-b682-973212477a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff1ecff4-a10c-451e-9e1f-ee0971a4bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0368690e-6fb3-411e-8894-545bfd8a6c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = torch.Tensor( testset.data ) / 256.0 - 0.5\n",
    "test_x = test_x.to(device)\n",
    "test_y = torch.Tensor( testset.targets ).long()\n",
    "test_y = test_y.to(device)\n",
    "train_x = torch.Tensor( trainset.data ) / 256.0 - 0.5\n",
    "train_x = train_x.to(device)\n",
    "train_y = torch.Tensor( trainset.targets ).long()\n",
    "train_y = train_y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b6377a8-1311-4d31-b15c-7086f4b5fcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x, y, batch_size):\n",
    "    n = x.shape[0]\n",
    "\n",
    "    batch_indices = random.sample( [ i for i in range(n) ], k = batch_size )\n",
    "\n",
    "    x_batch = x[ batch_indices ]\n",
    "    y_batch = y[ batch_indices ]\n",
    "\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf9c2d23-6de6-490a-95bd-f0be6ae05d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class layerTesting(nn.Module):\n",
    "    def __init__(self,k,m):\n",
    "        super(layerTesting, self).__init__()\n",
    "\n",
    "        self.layer_input = torch.nn.Linear( in_features = 28*28*1, out_features = m, bias=True )\n",
    "        self.layer_output = torch.nn.Linear( in_features = m, out_features = 10, bias=True )\n",
    "        self.linears = nn.ModuleList([nn.Linear(m, m) for i in range(k-1)])\n",
    "        self.normalize = nn.LayerNorm(m)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        output = nn.Flatten()( input_tensor )\n",
    "        output = self.layer_input(output)\n",
    "        output = nn.ELU()(output)\n",
    "        output = self.normalize(output)\n",
    "        for l in self.linears:\n",
    "            output = l(output)\n",
    "            output = nn.ELU()(output)\n",
    "            output = self.normalize(output)\n",
    "        output = self.layer_output(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4f7904e-74d5-4c40-a80a-3555ba27285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSoftmaxRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearSoftmaxRegression, self).__init__()\n",
    "\n",
    "        self.layer_1 = torch.nn.Linear( in_features = 28*28*1, out_features = 10, bias=True )\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        flattened = nn.Flatten()( input_tensor )\n",
    "\n",
    "        logits = self.layer_1( flattened )\n",
    "\n",
    "        return logits\n",
    "\n",
    "        # NOTE: Correcting a mistake I made previously, I am outputing the results of a linear layer,\n",
    "        # For softmax to be applied elsewhere. Shiwei correctly pointed out that if we use the built in\n",
    "        # cross entropy loss function, it expects to receive these linear values, and will apply\n",
    "        # logOfSoftmax internally when calculating the loss, so that we don't have to.\n",
    "\n",
    "        # But if we want the probabilities, we do need to apply softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fe7c3f7-4edc-4a5b-8971-939e11f90c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix( model, x, y ):\n",
    "    identification_counts = np.zeros( shape = (10,10), dtype = np.int32 )\n",
    "    \n",
    "    logits = model.forward( x )\n",
    "    predicted_classes = torch.argmax( logits, dim = 1 )\n",
    "\n",
    "    n = x.shape[0]\n",
    "\n",
    "    for i in range(n):\n",
    "        actual_class = int( y[i].item() )\n",
    "        predicted_class = predicted_classes[i].item()\n",
    "        identification_counts[actual_class, predicted_class] += 1\n",
    "\n",
    "    return identification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38314cfa-ace0-4c98-baa0-0351c8bf4ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Confusion Matrix\n",
      "[[ 10  27  13  20   2 284  60 161 369  34]\n",
      " [  8   0   0 451   0 130 494   0  52   0]\n",
      " [ 10   1   0 230   0 221 243 121 206   0]\n",
      " [ 47  27   1  77   2 310 148  26 372   0]\n",
      " [  4  18   0  57   5 447 172   9 270   0]\n",
      " [ 30  38   1  22   2 447 166  44 142   0]\n",
      " [ 25   5   0  43   1 259 354 125 146   0]\n",
      " [ 40  75   0 143  10 143 442   2 171   2]\n",
      " [ 27   6   1 116   1 290  41  35 457   0]\n",
      " [ 15  31   1  47   2 430 131   3 349   0]]\n"
     ]
    }
   ],
   "source": [
    "model3 = layerTesting(3,m_num(3,100000))\n",
    "model3.to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Initial Confusion Matrix\")\n",
    "print( confusion_matrix( model3, test_x, test_y ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dd8395-8e07-4689-ba5b-759aeea340fb",
   "metadata": {},
   "source": [
    "Based off of Dr.Cowan's suggestions, I'm using $P=100000$ and $k=1\\ldots 10$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cf0b669-f66f-40f5-8b60-c2eda0b5309c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 layer(s), total Loss over Batches: 117.06964395940304\n",
      "1 layer(s), total Loss over Batches: 70.60429352521896\n",
      "1 layer(s), total Loss over Batches: 61.5102037191391\n",
      "1 layer(s), total Loss over Batches: 52.71329865604639\n",
      "1 layer(s), total Loss over Batches: 45.71065382659435\n",
      "1 layer(s), total Loss over Batches: 39.896190501749516\n",
      "1 layer(s), total Loss over Batches: 33.85286169871688\n",
      "1 layer(s), total Loss over Batches: 30.32758166268468\n",
      "1 layer(s), total Loss over Batches: 24.785035204142332\n",
      "1 layer(s), total Loss over Batches: 23.931896209716797\n",
      "1 layer(s), total Loss over Batches: 22.247295025736094\n",
      "1 layer(s), total Loss over Batches: 19.903948541730642\n",
      "1 layer(s), total Loss over Batches: 18.489243168383837\n",
      "1 layer(s), total Loss over Batches: 17.714156134054065\n",
      "1 layer(s), total Loss over Batches: 15.916894627735019\n",
      "1 layer(s), total Loss over Batches: 14.08684323169291\n",
      "1 layer(s), total Loss over Batches: 13.337606210261583\n",
      "1 layer(s), total Loss over Batches: 12.04009018279612\n",
      "1 layer(s), total Loss over Batches: 11.801191508769989\n",
      "1 layer(s), total Loss over Batches: 10.04997458588332\n",
      "Current Confusion Matrix\n",
      "[[ 971    1    0    1    0    0    3    1    2    1]\n",
      " [   0 1121    2    2    0    1    3    0    6    0]\n",
      " [   5    1  996    9    1    0    3    9    7    1]\n",
      " [   0    0    1  995    0    3    0    3    5    3]\n",
      " [   1    0    3    0  937    0    3    3    1   34]\n",
      " [   4    0    0    7    1  871    2    2    2    3]\n",
      " [   6    3    0    0    5   13  927    0    4    0]\n",
      " [   1    1    7    4    0    0    0 1000    3   12]\n",
      " [   2    0    3    5    4    3    1    3  948    5]\n",
      " [   3    2    0    5    4    2    1    2    1  989]]\n",
      "\n",
      "2 layer(s), total Loss over Batches: 85.38971841335297\n",
      "2 layer(s), total Loss over Batches: 40.73843179643154\n",
      "2 layer(s), total Loss over Batches: 27.706841357052326\n",
      "2 layer(s), total Loss over Batches: 21.878696367144585\n",
      "2 layer(s), total Loss over Batches: 17.486464504152536\n",
      "2 layer(s), total Loss over Batches: 14.685323582962155\n",
      "2 layer(s), total Loss over Batches: 12.809410817921162\n",
      "2 layer(s), total Loss over Batches: 10.694638305343688\n",
      "2 layer(s), total Loss over Batches: 9.833968509919941\n",
      "2 layer(s), total Loss over Batches: 8.435695005580783\n",
      "2 layer(s), total Loss over Batches: 6.795865912921727\n",
      "2 layer(s), total Loss over Batches: 6.491763831116259\n",
      "2 layer(s), total Loss over Batches: 6.5429192231968045\n",
      "2 layer(s), total Loss over Batches: 4.964788680896163\n",
      "2 layer(s), total Loss over Batches: 4.40593624766916\n",
      "2 layer(s), total Loss over Batches: 4.872709356248379\n",
      "2 layer(s), total Loss over Batches: 4.367626374820247\n",
      "2 layer(s), total Loss over Batches: 3.3210695823654532\n",
      "2 layer(s), total Loss over Batches: 4.427401972003281\n",
      "2 layer(s), total Loss over Batches: 3.257534243981354\n",
      "Current Confusion Matrix\n",
      "[[ 973    0    1    0    0    1    2    1    1    1]\n",
      " [   0 1121    4    1    0    1    4    0    4    0]\n",
      " [   1    1 1017    0    4    0    3    3    3    0]\n",
      " [   1    0    7  992    0    2    0    1    3    4]\n",
      " [   0    1    2    1  965    0    4    1    1    7]\n",
      " [   3    0    0    9    2  864    8    1    3    2]\n",
      " [   2    2    0    0    4    1  948    0    1    0]\n",
      " [   1    4   10    1    2    0    0 1005    2    3]\n",
      " [   4    0    2    3    2    1    2    2  955    3]\n",
      " [   3    2    0    5    6    1    2    2    5  983]]\n",
      "\n",
      "3 layer(s), total Loss over Batches: 88.78311756253242\n",
      "3 layer(s), total Loss over Batches: 38.829535245895386\n",
      "3 layer(s), total Loss over Batches: 26.131853338330984\n",
      "3 layer(s), total Loss over Batches: 21.132500652223825\n",
      "3 layer(s), total Loss over Batches: 17.257720640860498\n",
      "3 layer(s), total Loss over Batches: 14.92600115481764\n",
      "3 layer(s), total Loss over Batches: 13.879514833912253\n",
      "3 layer(s), total Loss over Batches: 11.525505769997835\n",
      "3 layer(s), total Loss over Batches: 10.997013464570045\n",
      "3 layer(s), total Loss over Batches: 10.10518216714263\n",
      "3 layer(s), total Loss over Batches: 7.777494251728058\n",
      "3 layer(s), total Loss over Batches: 8.631398976780474\n",
      "3 layer(s), total Loss over Batches: 6.874691125936806\n",
      "3 layer(s), total Loss over Batches: 6.319163259118795\n",
      "3 layer(s), total Loss over Batches: 7.501037116162479\n",
      "3 layer(s), total Loss over Batches: 5.179358220426366\n",
      "3 layer(s), total Loss over Batches: 5.242844985798001\n",
      "3 layer(s), total Loss over Batches: 5.5756283877417445\n",
      "3 layer(s), total Loss over Batches: 4.833580562262796\n",
      "3 layer(s), total Loss over Batches: 5.15515618911013\n",
      "Current Confusion Matrix\n",
      "[[ 972    1    1    0    0    1    0    1    2    2]\n",
      " [   0 1128    0    4    0    0    1    1    1    0]\n",
      " [   0    0 1020    4    0    0    2    3    3    0]\n",
      " [   0    0    3  990    0    6    0    2    5    4]\n",
      " [   2    1    1    1  952    0    4    4    1   16]\n",
      " [   2    0    0    8    0  869    6    2    4    1]\n",
      " [   3    4    0    1    2    2  943    0    3    0]\n",
      " [   1    2    6    6    0    0    1 1004    4    4]\n",
      " [   3    0    2    7    0    2    1    2  954    3]\n",
      " [   3    2    0    3    3    2    0    4    3  989]]\n",
      "\n",
      "4 layer(s), total Loss over Batches: 88.67733136564493\n",
      "4 layer(s), total Loss over Batches: 38.7987045198679\n",
      "4 layer(s), total Loss over Batches: 27.53810752183199\n",
      "4 layer(s), total Loss over Batches: 20.87163694947958\n",
      "4 layer(s), total Loss over Batches: 17.89476791769266\n",
      "4 layer(s), total Loss over Batches: 16.106745986267924\n",
      "4 layer(s), total Loss over Batches: 14.001212413422763\n",
      "4 layer(s), total Loss over Batches: 12.46580751426518\n",
      "4 layer(s), total Loss over Batches: 11.168682233430445\n",
      "4 layer(s), total Loss over Batches: 10.284101076424122\n",
      "4 layer(s), total Loss over Batches: 8.659884728956968\n",
      "4 layer(s), total Loss over Batches: 9.167461581528187\n",
      "4 layer(s), total Loss over Batches: 7.947048665955663\n",
      "4 layer(s), total Loss over Batches: 7.80230610165745\n",
      "4 layer(s), total Loss over Batches: 6.39557142695412\n",
      "4 layer(s), total Loss over Batches: 6.0367275308817625\n",
      "4 layer(s), total Loss over Batches: 6.456485101953149\n",
      "4 layer(s), total Loss over Batches: 6.2169826603494585\n",
      "4 layer(s), total Loss over Batches: 5.272232812829316\n",
      "4 layer(s), total Loss over Batches: 4.241883374983445\n",
      "Current Confusion Matrix\n",
      "[[ 971    1    1    0    0    1    2    1    2    1]\n",
      " [   0 1132    1    0    0    0    1    0    1    0]\n",
      " [   3    2 1020    1    1    0    1    3    1    0]\n",
      " [   0    2   13  958    0   21    0    1   12    3]\n",
      " [   3    2    7    0  933    3    3    2    8   21]\n",
      " [   2    0    0    2    0  882    4    1    1    0]\n",
      " [   3    4    2    0    1    3  944    0    1    0]\n",
      " [   2    7   17    1    0    0    0  987    5    9]\n",
      " [   2    1    3    1    0    3    2    2  958    2]\n",
      " [   2    2    1    0    3    9    2    0   16  974]]\n",
      "\n",
      "5 layer(s), total Loss over Batches: 89.1308246999979\n",
      "5 layer(s), total Loss over Batches: 36.956029150635004\n",
      "5 layer(s), total Loss over Batches: 29.37217130884528\n",
      "5 layer(s), total Loss over Batches: 21.67424213141203\n",
      "5 layer(s), total Loss over Batches: 20.745128087699413\n",
      "5 layer(s), total Loss over Batches: 15.612670563161373\n",
      "5 layer(s), total Loss over Batches: 14.08331597596407\n",
      "5 layer(s), total Loss over Batches: 13.665844480507076\n",
      "5 layer(s), total Loss over Batches: 12.066499276086688\n",
      "5 layer(s), total Loss over Batches: 10.871633927803487\n",
      "5 layer(s), total Loss over Batches: 9.877996182069182\n",
      "5 layer(s), total Loss over Batches: 9.144358521793038\n",
      "5 layer(s), total Loss over Batches: 8.450718745589256\n",
      "5 layer(s), total Loss over Batches: 7.871814219281077\n",
      "5 layer(s), total Loss over Batches: 6.976352026918903\n",
      "5 layer(s), total Loss over Batches: 8.888279252685606\n",
      "5 layer(s), total Loss over Batches: 6.285314180189744\n",
      "5 layer(s), total Loss over Batches: 5.934999496908858\n",
      "5 layer(s), total Loss over Batches: 5.598659414914437\n",
      "5 layer(s), total Loss over Batches: 6.1645331250038\n",
      "Current Confusion Matrix\n",
      "[[ 965    1    5    0    0    1    4    1    1    2]\n",
      " [   0 1128    3    1    0    0    1    2    0    0]\n",
      " [   4    1 1023    0    1    0    1    1    1    0]\n",
      " [   0    0   11  988    0    2    0    3    2    4]\n",
      " [   1    0    4    0  966    0    5    2    0    4]\n",
      " [   2    0    0    6    2  874    5    1    1    1]\n",
      " [   2    3    2    0    3    8  940    0    0    0]\n",
      " [   0    1   24    2    0    0    1  993    3    4]\n",
      " [   1    0    8   10    1    8    3    3  936    4]\n",
      " [   3    3    2    7   14    0    2    8    0  970]]\n",
      "\n",
      "6 layer(s), total Loss over Batches: 95.66580751538277\n",
      "6 layer(s), total Loss over Batches: 38.6098236143589\n",
      "6 layer(s), total Loss over Batches: 28.28706021606922\n",
      "6 layer(s), total Loss over Batches: 23.347686709836125\n",
      "6 layer(s), total Loss over Batches: 20.62012585066259\n",
      "6 layer(s), total Loss over Batches: 17.241883715614676\n",
      "6 layer(s), total Loss over Batches: 15.052377653308213\n",
      "6 layer(s), total Loss over Batches: 14.421692690812051\n",
      "6 layer(s), total Loss over Batches: 13.016519781202078\n",
      "6 layer(s), total Loss over Batches: 12.007848136126995\n",
      "6 layer(s), total Loss over Batches: 10.924053960479796\n",
      "6 layer(s), total Loss over Batches: 10.214128280058503\n",
      "6 layer(s), total Loss over Batches: 9.792128501459956\n",
      "6 layer(s), total Loss over Batches: 8.953086835797876\n",
      "6 layer(s), total Loss over Batches: 7.540204589720815\n",
      "6 layer(s), total Loss over Batches: 8.08989135781303\n",
      "6 layer(s), total Loss over Batches: 7.470129601075314\n",
      "6 layer(s), total Loss over Batches: 6.487635761266574\n",
      "6 layer(s), total Loss over Batches: 6.963119306601584\n",
      "6 layer(s), total Loss over Batches: 6.194967687712051\n",
      "Current Confusion Matrix\n",
      "[[ 973    0    0    0    1    0    1    0    2    3]\n",
      " [   2 1128    0    0    0    0    1    1    1    2]\n",
      " [   7    5  988    7    2    0    3    8    8    4]\n",
      " [   0    1    1  979    0    3    0    7    6   13]\n",
      " [   1    0    7    0  953    1    3    4    0   13]\n",
      " [   3    1    0   11    0  848    5    1    7   16]\n",
      " [   5    3    0    1    5    2  938    0    4    0]\n",
      " [   0    5    7    1    1    0    0  983    1   30]\n",
      " [   4    1    2    2    7    3    1    2  940   12]\n",
      " [   2    1    0    1    8    1    1    1    0  994]]\n",
      "\n",
      "7 layer(s), total Loss over Batches: 93.72475049644709\n",
      "7 layer(s), total Loss over Batches: 39.03898410499096\n",
      "7 layer(s), total Loss over Batches: 30.5653932467103\n",
      "7 layer(s), total Loss over Batches: 23.45578157156706\n",
      "7 layer(s), total Loss over Batches: 19.901955392211676\n",
      "7 layer(s), total Loss over Batches: 17.56513655744493\n",
      "7 layer(s), total Loss over Batches: 16.35001834668219\n",
      "7 layer(s), total Loss over Batches: 14.5791802033782\n",
      "7 layer(s), total Loss over Batches: 14.294213741086423\n",
      "7 layer(s), total Loss over Batches: 13.315793028101325\n",
      "7 layer(s), total Loss over Batches: 10.925079744309187\n",
      "7 layer(s), total Loss over Batches: 12.032539002597332\n",
      "7 layer(s), total Loss over Batches: 9.309157442301512\n",
      "7 layer(s), total Loss over Batches: 9.31498787086457\n",
      "7 layer(s), total Loss over Batches: 9.299844137392938\n",
      "7 layer(s), total Loss over Batches: 8.721339367330074\n",
      "7 layer(s), total Loss over Batches: 9.412701916415244\n",
      "7 layer(s), total Loss over Batches: 8.573896567104384\n",
      "7 layer(s), total Loss over Batches: 6.040356137789786\n",
      "7 layer(s), total Loss over Batches: 7.224296289496124\n",
      "Current Confusion Matrix\n",
      "[[ 975    1    0    0    1    0    1    0    1    1]\n",
      " [   0 1127    0    3    1    0    1    0    3    0]\n",
      " [   4    2  994    6    4    0    3    9   10    0]\n",
      " [   0    0    2  995    0    2    0    5    3    3]\n",
      " [   0    0    1    0  967    0    5    8    1    0]\n",
      " [   3    0    0    9    1  871    3    1    3    1]\n",
      " [   2    2    0    1    4    3  944    0    2    0]\n",
      " [   1    6    7    1    3    0    0 1007    2    1]\n",
      " [   0    0    1    5    2    6    1    3  954    2]\n",
      " [   4    2    0    6   18    2    4   11    7  955]]\n",
      "\n",
      "8 layer(s), total Loss over Batches: 94.2525414377451\n",
      "8 layer(s), total Loss over Batches: 39.3185104355216\n",
      "8 layer(s), total Loss over Batches: 27.87123753875494\n",
      "8 layer(s), total Loss over Batches: 23.589765422046185\n",
      "8 layer(s), total Loss over Batches: 20.35750076547265\n",
      "8 layer(s), total Loss over Batches: 17.578647984191775\n",
      "8 layer(s), total Loss over Batches: 16.385086378082633\n",
      "8 layer(s), total Loss over Batches: 15.620522557757795\n",
      "8 layer(s), total Loss over Batches: 13.477696226909757\n",
      "8 layer(s), total Loss over Batches: 12.255784975364804\n",
      "8 layer(s), total Loss over Batches: 12.398288340307772\n",
      "8 layer(s), total Loss over Batches: 12.125199251808226\n",
      "8 layer(s), total Loss over Batches: 12.470038881525397\n",
      "8 layer(s), total Loss over Batches: 9.014221052639186\n",
      "8 layer(s), total Loss over Batches: 9.460203102324158\n",
      "8 layer(s), total Loss over Batches: 9.051593331620097\n",
      "8 layer(s), total Loss over Batches: 8.881543942261487\n",
      "8 layer(s), total Loss over Batches: 7.970928394468501\n",
      "8 layer(s), total Loss over Batches: 8.262173425871879\n",
      "8 layer(s), total Loss over Batches: 7.783812558744103\n",
      "Current Confusion Matrix\n",
      "[[ 970    0    2    0    0    0    1    0    6    1]\n",
      " [   0 1128    0    0    0    1    2    3    0    1]\n",
      " [   1    4 1015    2    3    1    1    1    4    0]\n",
      " [   2    1    5  958    0   29    0    2    5    8]\n",
      " [   1    0    2    0  952    0    4    4    0   19]\n",
      " [   2    0    0    3    0  873    4    0    7    3]\n",
      " [   5    3    1    1    1    4  941    0    2    0]\n",
      " [   2    3    8    1    0    0    0  992   10   12]\n",
      " [   0    0    3    0    0    1    0    2  966    2]\n",
      " [   2    2    0    0    6    5    2    2    9  981]]\n",
      "\n",
      "9 layer(s), total Loss over Batches: 93.88425904512405\n",
      "9 layer(s), total Loss over Batches: 38.86909735202789\n",
      "9 layer(s), total Loss over Batches: 29.270908303558826\n",
      "9 layer(s), total Loss over Batches: 25.079274754971266\n",
      "9 layer(s), total Loss over Batches: 21.641668451949954\n",
      "9 layer(s), total Loss over Batches: 18.910276466980577\n",
      "9 layer(s), total Loss over Batches: 17.170744577422738\n",
      "9 layer(s), total Loss over Batches: 16.485228080302477\n",
      "9 layer(s), total Loss over Batches: 14.171441148035228\n",
      "9 layer(s), total Loss over Batches: 14.337712035514414\n",
      "9 layer(s), total Loss over Batches: 12.345505461096764\n",
      "9 layer(s), total Loss over Batches: 11.89005919592455\n",
      "9 layer(s), total Loss over Batches: 10.946653596591204\n",
      "9 layer(s), total Loss over Batches: 10.90982573106885\n",
      "9 layer(s), total Loss over Batches: 11.545822677202523\n",
      "9 layer(s), total Loss over Batches: 10.08205938898027\n",
      "9 layer(s), total Loss over Batches: 9.045361033640802\n",
      "9 layer(s), total Loss over Batches: 7.57949676271528\n",
      "9 layer(s), total Loss over Batches: 8.149946200661361\n",
      "9 layer(s), total Loss over Batches: 8.383198027033359\n",
      "Current Confusion Matrix\n",
      "[[ 973    1    0    1    1    0    1    0    2    1]\n",
      " [   3 1123    1    2    1    0    1    2    1    1]\n",
      " [   5    0  990   16    1    0    0   16    4    0]\n",
      " [   4    1    4  975    0    4    0    7   11    4]\n",
      " [   2    1    3    0  943    0    1    3    1   28]\n",
      " [   3    0    0   21    0  848    6    2    6    6]\n",
      " [   5    4    1    1    8    4  931    0    4    0]\n",
      " [   2    3    3    3    2    0    0 1002    3   10]\n",
      " [   3    0    2    3    0    1    0    5  956    4]\n",
      " [   5    0    0    4    3    2    1    1    5  988]]\n",
      "\n",
      "10 layer(s), total Loss over Batches: 100.71893653273582\n",
      "10 layer(s), total Loss over Batches: 41.770766697824\n",
      "10 layer(s), total Loss over Batches: 30.82134300097823\n",
      "10 layer(s), total Loss over Batches: 26.058751165866852\n",
      "10 layer(s), total Loss over Batches: 23.62414000928402\n",
      "10 layer(s), total Loss over Batches: 21.515163630247116\n",
      "10 layer(s), total Loss over Batches: 18.28835378587246\n",
      "10 layer(s), total Loss over Batches: 15.77194345369935\n",
      "10 layer(s), total Loss over Batches: 15.516982172615826\n",
      "10 layer(s), total Loss over Batches: 14.631810002028942\n",
      "10 layer(s), total Loss over Batches: 12.734329499304295\n",
      "10 layer(s), total Loss over Batches: 13.522727988660336\n",
      "10 layer(s), total Loss over Batches: 12.247738484293222\n",
      "10 layer(s), total Loss over Batches: 11.198255891911685\n",
      "10 layer(s), total Loss over Batches: 10.246037976350635\n",
      "10 layer(s), total Loss over Batches: 11.100698697846383\n",
      "10 layer(s), total Loss over Batches: 9.475206077564508\n",
      "10 layer(s), total Loss over Batches: 8.87517643161118\n",
      "10 layer(s), total Loss over Batches: 8.679981998866424\n",
      "10 layer(s), total Loss over Batches: 8.483681324636564\n",
      "Current Confusion Matrix\n",
      "[[ 973    0    0    1    0    1    3    0    1    1]\n",
      " [   0 1127    1    2    0    2    2    0    1    0]\n",
      " [   2    1 1021    2    2    0    1    3    0    0]\n",
      " [   2    0    7  985    0    7    0    2    5    2]\n",
      " [   0    0    2    0  962    0    6    2    0   10]\n",
      " [   2    0    0    6    0  871    6    1    3    3]\n",
      " [   4    3    0    1    5    5  939    0    1    0]\n",
      " [   0   12   13    3    0    0    1  987    2   10]\n",
      " [   5    0    4    8    2    2    2    3  946    2]\n",
      " [   2    2    0    4    5    1    1    1    3  990]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "P = 100000\n",
    "batch_size = 256\n",
    "finalLossTest = []\n",
    "finalLossTrain = []\n",
    "for k in range(1,10+1):\n",
    "    model = layerTesting(k,m_num(k,P))\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.0005 )\n",
    "    for epochs in range(20):\n",
    "        total_loss = 0\n",
    "        for batch in range( train_x.shape[0] // batch_size ):\n",
    "            x_batch, y_batch = get_batch(train_x, train_y, batch_size)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            logits = model( x_batch )\n",
    "            loss = loss_function( logits, y_batch )\n",
    "    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            total_loss += loss.item()\n",
    "    \n",
    "        print( k,\"layer(s), total Loss over Batches:\",total_loss )\n",
    "    finalLossTest.append(loss_function(model(test_x), test_y))\n",
    "    finalLossTrain.append(loss_function(model(train_x), train_y))\n",
    "    print(\"Current Confusion Matrix\")\n",
    "    print( confusion_matrix( model, test_x, test_y ) )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "70c1c91f-7abd-41a8-a4c4-80226205b64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08009275794029236\n"
     ]
    }
   ],
   "source": [
    "print(finalLoss[1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c120e3c-6b5e-4c53-91ff-c149ed8abaad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'testing loss')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(1,11)],[j.item() for j in finalLossTest],'o')\n",
    "plt.xlabel(\"k values\")\n",
    "plt.ylabel(\"testing loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c4adee1-3a66-4c24-a11b-5622251ec441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'training loss')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(1,11)],[j.item() for j in finalLossTrain],'o')\n",
    "plt.xlabel(\"k values\")\n",
    "plt.ylabel(\"training loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4ea849-571a-43dd-b48d-05c0bab30963",
   "metadata": {},
   "source": [
    "Now for comparison with the no hidden layers linear model:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
