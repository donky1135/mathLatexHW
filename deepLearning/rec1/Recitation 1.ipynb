{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjwAZHghRJlw"
   },
   "source": [
    "# Intro to Deep Learning - Recitation\n",
    "TA: Shiwei Tan (shiwei.tan@rutgers.edu)\n",
    "\n",
    "## Intro to Colab\n",
    "+ Code & Text & Image\n",
    "+ Context & Execution Order\n",
    "+ Long-running Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHfnYAfHSr4u"
   },
   "source": [
    "## Intro to Pytorch\n",
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "j8-umUPVRjVZ"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SvEDNr-yRvgt",
    "outputId": "9d88a26e-0b3c-48a9-b574-96228c5fd6b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 5, 9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = torch.tensor([1, 5, 9])\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qch05ra4U1_t",
    "outputId": "51ee9f56-b44b-4cd0-c4ad-8d78836fafad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tpZCeGvbVJ5N",
    "outputId": "b550348b-e22e-45e8-dac3-59d293e5270e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "zeros_vec = torch.zeros(6)\n",
    "print(zeros_vec)\n",
    "ones_mat = torch.ones((4, 6))\n",
    "print(ones_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KeQSUrrlWDE4",
    "outputId": "7b9dfceb-977f-48cc-c6c3-2c1f371bf90f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "like = torch.zeros_like(ones_mat)\n",
    "print(like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jBWIZiQYZkae",
    "outputId": "591a9c84-6c86-4036-99d7-a76dcee45bc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "[1, 1]: tensor(5)\n",
      "[1]: tensor([4, 5, 6])\n",
      "[1, :]: tensor([4, 5, 6])\n",
      "[:, 1]: tensor([2, 5, 8])\n",
      "[:2, :]:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "print(mat)\n",
    "print(\"[1, 1]:\", mat[1, 1])\n",
    "print(\"[1]:\", mat[1])\n",
    "print(\"[1, :]:\", mat[1, :])\n",
    "print(\"[:, 1]:\", mat[:, 1])\n",
    "print(\"[:2, :]:\", mat[:2, :], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JH2qMXmWgcc"
   },
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NP9HR1aRWimt",
    "outputId": "447fe5b6-9fa9-4ee0-eaeb-407dd4ca9786"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "\n",
      "1. tensor([3., 3., 3., 3., 3.])\n",
      "2. tensor([5., 5., 5., 5., 5.])\n",
      "3. tensor([4., 4., 4., 4., 4.])\n",
      "4. tensor([16., 16., 16., 16., 16.])\n",
      "5. tensor([4., 4., 4., 4., 4.])\n",
      "6. tensor([0.8415, 0.8415, 0.8415, 0.8415, 0.8415])\n",
      "7. tensor([4., 4., 4., 4., 4.])\n"
     ]
    }
   ],
   "source": [
    "ones_vec = torch.ones(5)\n",
    "twos_vec = torch.ones(5) * 2\n",
    "print(ones_vec)\n",
    "print(twos_vec)\n",
    "print()\n",
    "\n",
    "# Element-wise Operations\n",
    "print(\"1.\", ones_vec + twos_vec)\n",
    "print(\"2.\", ones_vec + 4)\n",
    "print(\"3.\", twos_vec * twos_vec)\n",
    "print(\"4.\", twos_vec ** 4)\n",
    "print(\"5.\", twos_vec ** twos_vec)\n",
    "print(\"6.\", torch.sin(ones_vec))\n",
    "print(\"7.\", torch.square(twos_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aWAt3D8-ZInV",
    "outputId": "9d3b2213-4eb2-47c3-92b7-350d2deb97f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "tensor(10.)\n",
      "tensor(2.)\n",
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "print(twos_vec)\n",
    "print(twos_vec.sum())\n",
    "print(twos_vec.mean())\n",
    "print(twos_vec.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OX7xArrBX3jk",
    "outputId": "a2023f52-1f26-41cd-a604-fefebfdfee2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "torch.Size([16])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "torch.Size([4, 4])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n"
     ]
    }
   ],
   "source": [
    "vec = torch.tensor(list(range(16)))\n",
    "print(vec)\n",
    "print(vec.shape)\n",
    "\n",
    "mat = vec.reshape((4, 4)) # vec itself is not changed!\n",
    "print(mat)\n",
    "print(mat.shape)\n",
    "print(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-nvhtIT0Y6rh",
    "outputId": "55a94d48-285a-4d0a-85a9-279af94a69b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "tensor([[ 0,  4,  8, 12],\n",
      "        [ 1,  5,  9, 13],\n",
      "        [ 2,  6, 10, 14],\n",
      "        [ 3,  7, 11, 15]])\n",
      "tensor([[ 56,  62,  68,  74],\n",
      "        [152, 174, 196, 218],\n",
      "        [248, 286, 324, 362],\n",
      "        [344, 398, 452, 506]])\n",
      "tensor([[ 56,  62,  68,  74],\n",
      "        [152, 174, 196, 218],\n",
      "        [248, 286, 324, 362],\n",
      "        [344, 398, 452, 506]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix Operations\n",
    "print(mat)\n",
    "print(mat.T)\n",
    "print(mat @ mat)\n",
    "print(torch.mm(mat, mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5ddhWHFbX3w"
   },
   "source": [
    "Concatenation, stacking, etc.\n",
    "\n",
    "Check the document if you are unsure:\n",
    "\n",
    "https://pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38JAZz9Xc1HH"
   },
   "source": [
    "### Gradient Information\n",
    "Pytorch can automatically track your computational graph and the gradient data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uvsqcpacdSKU",
    "outputId": "24ea114f-af83-4be2-aaae-444e33a7e12b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([1.], requires_grad=True)\n",
      "tensor([1.], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.nn.Parameter(torch.tensor([1.]), requires_grad=True)\n",
    "print(x)\n",
    "print(x * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iCWwTHJddqSd",
    "outputId": "2c6c330a-afcb-4abf-9a99-a81432d484fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x * x + 5 * x\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V8FUNNUwduZ4",
    "outputId": "ed0e3f4c-e41b-4c21-90ad-8925de76f6f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This y.backward() calculates dy/d(node output) for every node.\n",
    "# Every operation in your expressions that calculate y produces a resulting value and a corresponding node.\n",
    "# For example, the expression x * x produces a node in the computational graph.\n",
    "# That node will be connected with the two operand nodes (x and the same x), and another node created by the '+' operator later will be connected to this node, too.\n",
    "# When you call .backward(), Pytorch will search from the y node and update the dy/d(node output) for each node it found.\n",
    "# This is why we can then read x.grad to get dy/dx.\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9XSoJL_hbKZ"
   },
   "source": [
    "## Example Gradient Descent - Calculating $\\sqrt2$\n",
    "Let's say we want to calculate the value of $\\sqrt2$.\n",
    "\n",
    "If we have: $f(x)=(x^2-2)^2$, then we can find the $\\sqrt2$ by minimizing $f(x)$.\n",
    "\n",
    "We minimize $f(x)$ by stepping $x$ to the direction that decreases $f(x)$. The direction can be known by caculating $f'(x)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "suwLpdLnitVk",
    "outputId": "93876660-175e-46c9-a28e-3fa3e2cec30a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f( 1.0 ) =  1.0\n",
      "f( 1.2000000476837158 ) =  0.31359994411468506\n",
      "f( 1.3344000577926636 ) =  0.04812602326273918\n",
      "f( 1.3929471969604492 ) =  0.003563863690942526\n",
      "f( 1.4095784425735474 ) =  0.00017131102504208684\n",
      "f( 1.4132683277130127 ) =  7.143176844692789e-06\n",
      "f( 1.414023756980896 ) =  2.8815361474698875e-07\n",
      "f( 1.4141755104064941 ) =  1.158765883246815e-08\n",
      "f( 1.4142059087753296 ) =  4.707203515863512e-10\n",
      "f( 1.4142119884490967 ) =  1.9454660105111543e-11\n",
      "f( 1.4142131805419922 ) =  1.1510792319313623e-12\n",
      "f( 1.4142135381698608 ) =  1.4210854715202004e-14\n",
      "f( 1.4142135381698608 ) =  1.4210854715202004e-14\n",
      "f( 1.4142135381698608 ) =  1.4210854715202004e-14\n",
      "f( 1.4142135381698608 ) =  1.4210854715202004e-14\n",
      "1.4142135623730951\n"
     ]
    }
   ],
   "source": [
    "x = torch.nn.Parameter(torch.Tensor([1.0]), requires_grad = True)\n",
    "\n",
    "def f(x):\n",
    "    return torch.square(x * x - 2)\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "for i in range(15):\n",
    "  f_value = f(x)\n",
    "  print(\"f(\", x.data.item(), \") = \", f_value.data.item())\n",
    "\n",
    "  f_value.backward()\n",
    "\n",
    "  #print(\"f'(\", x.data.item(), \") = \", x.grad.item())\n",
    "\n",
    "  #print()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    # We don't need Pytorch to track the computational graph for this multiplication, so we do this in a no_grad() context.\n",
    "    x -= alpha * x.grad\n",
    "\n",
    "  # .backward() accumulates the gradient on the param.grad rather than directly setting param.grad to the gradient, so we need to clear the gradient before we do the next .backward().\n",
    "  x.grad = None\n",
    "\n",
    "print(2 ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SE5eS9wZkfJx"
   },
   "source": [
    "## Another Example of Gradient Descent - Finding the Midpoint\n",
    "Suppost we have 3 points and we want to find a midpoint that minimizes the total squared distance to these 3 points. How do we find it?\n",
    "\n",
    "We minimizing the funtion: $f(p)=||p-p_1||^2+||p-p_2||^2+||p-p_3||^2$.\n",
    "\n",
    "We use gradient descent again! It's just that now we have 2 variables to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JH_kPECIlma-",
    "outputId": "dce27136-e561-45e2-b1c1-c17c03d045ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Distance: tensor(26.8940, grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.4270, 1.5657], requires_grad=True)\n",
      "Total Distance: tensor(16.7941, grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.6914, 2.5350], requires_grad=True)\n",
      "Total Distance: tensor(13.8641, grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.8338, 3.0572], requires_grad=True)\n",
      "Total Distance: tensor(13.0140, grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.9105, 3.3384], requires_grad=True)\n",
      "Total Distance: tensor(12.7674, grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.9518, 3.4898], requires_grad=True)\n",
      "Total Distance: tensor(12.6959, grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.9740, 3.5714], requires_grad=True)\n",
      "Total Distance: tensor(12.6751, grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.9860, 3.6154], requires_grad=True)\n",
      "Total Distance: tensor(12.6691, grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.9925, 3.6390], requires_grad=True)\n",
      "Total Distance: tensor(12.6674, grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.9959, 3.6518], requires_grad=True)\n",
      "Total Distance: tensor(12.6669, grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.9978, 3.6587], requires_grad=True)\n",
      "Total Distance: tensor(12.6667, grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.9988, 3.6623], requires_grad=True)\n",
      "Total Distance: tensor(12.6667, grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.9994, 3.6643], requires_grad=True)\n",
      "Total Distance: tensor(12.6667, grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.9997, 3.6654], requires_grad=True)\n",
      "Total Distance: tensor(12.6667, grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.9998, 3.6660], requires_grad=True)\n",
      "Total Distance: tensor(12.6667, grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.9999, 3.6663], requires_grad=True)\n",
      "tensor([1.0000, 3.6667])\n"
     ]
    }
   ],
   "source": [
    "point_1 = torch.Tensor([1,2])\n",
    "point_2 = torch.Tensor([3,4])\n",
    "point_3 = torch.Tensor([-1,5])\n",
    "\n",
    "\n",
    "distance_minimizer = torch.nn.Parameter(torch.Tensor([0,0]), requires_grad = True)\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "for i in range(150):\n",
    "  distance_1 = torch.sum( torch.square( point_1 - distance_minimizer ) )\n",
    "  distance_2 = torch.sum( torch.square( point_2 - distance_minimizer ) )\n",
    "  distance_3 = torch.sum( torch.square( point_3 - distance_minimizer ) )\n",
    "\n",
    "  total_distance = distance_1 + distance_2 + distance_3\n",
    "\n",
    "  if (i + 1) % 10 == 0:\n",
    "    print(\"Total Distance:\", total_distance)\n",
    "    print( distance_minimizer )\n",
    "\n",
    "  total_distance.backward()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    distance_minimizer -= alpha * distance_minimizer.grad\n",
    "\n",
    "  distance_minimizer.grad = None\n",
    "\n",
    "print( (point_1 + point_2 + point_3)/3 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuaEbSVDpTox"
   },
   "source": [
    "## Review\n",
    "- Colab\n",
    "- Pytorch tensors\n",
    "- Auto-differentiation\n",
    "- Gradient descent examples\n",
    "\n",
    "TA:\\\n",
    "Shiwei Tan\\\n",
    "shiwei.tan@rutgers.edu\\\n",
    "Office hour: Thursday 3pm - 4pm, CBIM\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
