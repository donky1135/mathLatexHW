\documentclass[12pt, letterpaper]{article}
\date{\today}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{cancel}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{pgfplots}
\usepackage{booktabs}
\usepackage{pifont}
\usepackage{amsthm,latexsym,amsfonts,graphicx,epsfig,comment}
\pgfplotsset{compat=1.16}
\usepackage{xcolor}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows.meta,arrows}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Po}{\mathcal{P}}
\newcommand{\Pro}{\mathbb{P}}
\author{Alex Valentino}
\title{477 homework}
\pagestyle{fancy}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\fancyhf{}
\rhead{
	Homework 8\\
	477	
}
\lhead{
	Alex Valentino\\
}
\begin{document}
Lemma: $\int_0^\infty xe^{-\lambda x} = \frac{-1}{\lambda}(xe^{-\lambda x})|_{0}^\infty + \frac{1}{\lambda} \int_0^\infty e^{-\lambda x}dx = 0 + \frac{1}{\lambda}\int_0^\infty e^{-\lambda x}dx = \frac{1}{\lambda^2}$.
\begin{enumerate}
	\item[6.2] 
	\begin{itemize}
		\item The respective p.m.fs of $X$ and $Y$:
		$$p_X (1) = \frac{1}{3},p_X (2) = \frac{1}{2}, p_X (3) = \frac{1}{6}$$ $$p_y(0) = \frac{1}{5},p_y(1) = \frac{1}{5},p_y(2) = \frac{1}{3},p_y(3) = \frac{4}{15}. $$
		\item Note that the $X,Y$ pairs satisfying the condition are as follows:
		$(1,0),(2,0),(1,1)$.  Thus the probability of $\Pro(X+Y^2 \leq 2) = \Pro(X = 1, Y=0) + \Pro(X=2, Y=0) + \Pro(X=1, Y=1) = \frac{1}{15} + \frac{1}{10} + \frac{1}{15} = \frac{7}{30}$
	\end{itemize}
	\item[6.6] 
	\begin{enumerate}
		\item $$f_X(x) = \int_0^\infty xe^{-x(y+1)} dy = xe^{-x}\int_0^\infty e^{-xy}dy = xe^{-x} \frac{1}{x} = e^{-x} $$
		$$\text{ by the cdf of the exponential distribution}$$
		$$f_Y = \int_0^\infty xe^{-x(y+1)} dx = \frac{1}{(1+y)^2} \text{ by the lemma}$$
		\item  $$\E[XY] = \int_0^\infty \int_0^\infty x^2y e^{-x(y+1)} dy dx = \int_0^\infty x^2 e^{-x} \int_0^\infty ye^{-xy} dy dx =  \int_0^\infty e^{-x}   = 1 \text{ by the lemma}$$
	\end{enumerate}
	\item[6.10] 
	\begin{itemize}
		\item The joint density is given by $f(x,y) = \begin{cases} 1 & \text{if } (x,y) \in (0,1)^2\\
		0 & \text{otherwise} \end{cases}$, since the area of the interior of the unit square is 1.  
		\item The probability $\Pro(X < Y)$ is given by the integral $\int_0^1 \int_0^y f(x,y) dx dy$.  This evaluates to $\int_0^1 \int_0^y f(x,y) dx dy = \int_0^1 y dy = \frac{1}{2}$.  
	\end{itemize}
	\item[6.12] We claim that $X \sim Exp(1)$ and $Y \sim Exp(2)$.  Note that for $x > 0$ and $y>0$ that $f_X(x)f_Y(y) = e^{-x}2e^{-2y} = 2e^{-(x+2y)} = f_{X,Y}(x,y)$.  Similarly if either $x\leq 0$ or $y \leq 0$ then $f_X(x)f_Y(y) = 0 = f_{X,Y}(x,y)$.  Since we have found the marginal distributions for $X,Y$ and we have shown 
	that the joint density function is separable then $X$ is independent of $Y$.
	\item[6.18] Let $f_{X,Y}(a,b)$ be the alleged joint probability mass function.
	\begin{enumerate}
		\item Note that if $a \in [4]$ then $\frac{1}{4a} \geq 0$, and otherwise $a \geq 0$.  Additionally, $\sum_{a=1}^4 \sum_{b=1}^a \frac{1}{4a} = \sum_{a=1}^4 a \frac{1}{4a} = \sum_{a=1}^4 \frac{1}{4} = 1$.  Therefore $f_{X,Y}$ is a pmf.
		\item The pmf for $X$ is given by $p_X(a) = \sum_{b=1}^a = \frac{1}{4a} = \frac{1}{4}$.  The pmf for $Y$ is given by $p_Y(1) = \frac{25}{48}, p_Y(2) = \frac{13}{48}, p_Y(3) = \frac{7}{48}, p_Y(4) = \frac{1}{16}$.
		\item $\Pro(X = Y+1) = \sum_{i=1}^3 \Pro(Y=i, X=i+1) = \frac{1}{8} +\frac{1}{12} +\frac{1}{16} = \frac{13}{48}$
	\end{enumerate}	 
	\item[6.30]
	Note that $f_X(k) = (1-p)^{k-1}p, f_Y(k) = e^{-\lambda}\frac{\lambda^k}{k!}$.
	Since we defined $X,Y$ to be independent then 
	$f_{X,Y}(m,n) = f_X(m)f_Y(n) =(1-p)^{m-1}pe^{-\lambda}\frac{\lambda^n}{n!}$.
	Note that since $X+1 = Y$, then we can find the probability by indexing over  		$f(n+1,n)$, which satisfies $X=Y+1$.  Therefore 
	\begin{align*}
		\Pro(X=Y+1) &= \sum_{n=0}^\infty f(n+1,n)\\
		 &= \sum_{n=0}^\infty(1-p)^{n}pe^{-\lambda}\frac{\lambda^n}{n!}\\
		 &= pe^{-\lambda} \sum_{n=0}^\infty \frac{(\lambda(1-p))^n}{n!}\\
		 &= pe^{-\lambda} e^{\lambda(1-p)}\\
		 &= pe^{-\lambda p}
	\end{align*}		
	\item[6.36] 
	\begin{enumerate}
		\item Note that 
		\begin{align*}
			c &= \int_{-\infty}^\infty \int_{-\infty}^\infty e^{-\frac{x^2}{2}-\frac{(x-y)^2}{2}}dydx\\ &=  \int_{-\infty}^\infty e^{-\frac{x^2}{2}} \int_{-\infty}^\infty e^{xy-\frac{y^2}{2}} dy dx \\
			&= \int_{-\infty}^\infty e^\frac{-x^2}{2} \sqrt{2\pi} e^{x^2} \text{ by HW 1}\\
			&= 1
		\end{align*}
		\item \begin{align*}
			f_Y(y) &= e^{\frac{-y^2}{2}} \int_{-\infty}^\infty e^{xy-x^2} dx\\
			&= \frac{e^{\frac{-y^2}{2}}}{\sqrt{2}} \int_{-\infty}^\infty e^{\frac{y}{\sqrt{2}u - \frac{u^2}{2}}} du\\
			&= \sqrt{\pi} e^{\frac{-y^2}{4}}
		\end{align*}
		\begin{align*}
			f_X(x) &= e^{-\frac{x^2}{2}} \int_{-\infty}^\infty e^{xy - x^2/2} dx\\
			&= \sqrt{2 \pi} e^{\frac{-x^2}{2}}
		\end{align*}
		\item Note that $f_X(x) f_Y(y) = \sqrt{2}\pi e^{-\frac{x^2}{2}-\frac{y^2}{4}} \neq e^{-\frac{x^2}{2}-\frac{(x-y)^2}{2}} = f_{X,Y}(x,y)$.  Thus the distributions are not independent.  
	\end{enumerate}
\end{enumerate}
\end{document}
